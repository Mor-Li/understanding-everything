<h1>examples/multimodal/nvlm/nvlm_prompts.json</h1>
<p>这份文件看着确实全是英文和代码符号，很容易让人发晕。但其实它的核心逻辑非常简单。</p>
<p>简单来说，这是一个<strong>“AI 话术训练手册”</strong>。</p>
<p>为了训练一个能看懂图片、又能聊天的 AI（多模态大模型），我们需要教它怎么听懂人类的指令。这个文件里装的，就是<strong>成百上千种“提问的方式”</strong>。</p>
<p>为了让你彻底搞懂，我制定了一个 <strong>5 步学习 Task List (任务清单)</strong>，我们一步步来拆解：</p>
<hr />
<h3>✅ Task 1: 理解文件的核心作用</h3>
<p><strong>目标</strong>：明白为什么要写这么多重复的话。</p>
<ul>
<li><strong>背景</strong>：你正在训练一个 AI。如果你只教它一句话：“请描述这张图”，那以后用户如果问：“图里有啥？”，AI 可能就听不懂了。</li>
<li><strong>作用</strong>：这个文件是为了<strong>增加数据的多样性</strong>。</li>
<li><strong>核心逻辑</strong>：<ul>
<li>把“描述这张图”这个指令，换成 100 种不同的说法（比如“简单说说图里发生了什么”、“给这张图写个标题”）。</li>
<li>在训练时，随机抽一句话喂给 AI，防止 AI 死记硬背，让它学会变通。</li>
</ul>
</li>
</ul>
<hr />
<h3>✅ Task 2: 拆解第一类能力——看图说话 (Captioning)</h3>
<p><strong>目标</strong>：看懂 <code>Captioning</code> 相关的部分。</p>
<p>在文件中，你会看到 <code>Captioning</code>、<code>CaptioningPretraining</code>、<code>CaptioningSFT</code> 等。
*   <strong>含义</strong>：Captioning 就是<strong>图像描述</strong>。即给 AI 一张图，让它说出图里有什么。
*   <strong>例子解析</strong>：
    *   <code>"Describe what's happening in this image in one short sentence."</code> (用简短的一句话描述图里发生了什么)
    *   <code>"Write a short caption that accurately represents the content of this image."</code> (写一个能精准代表图片内容的标题)
*   <strong>区别</strong>：
    *   <code>CaptioningPretraining</code>（预训练）：通常要求简短、直接，用来打基础。
    *   <code>CaptioningDetailed</code>（详细描述）：要求 AI 写长段落，不仅要说“有只猫”，还要说“猫在阳光下睡觉，看起来很惬意”，训练 AI 的细节观察力和文笔。</p>
<hr />
<h3>✅ Task 3: 拆解第二类能力——看图问答 (VQA)</h3>
<p><strong>目标</strong>：看懂 <code>VQAPretraining</code> 和 <code>VQASFT</code>。</p>
<ul>
<li><strong>含义</strong>：VQA = Visual Question Answering (<strong>视觉问答</strong>)。即用户指着图提问，AI 回答。</li>
<li><strong>符号解析</strong>：注意看里面的 <code>{}</code> 符号。<ul>
<li><code>"Question: {} Short answer:"</code></li>
<li>这里的 <code>{}</code> 是一个<strong>占位符</strong>。训练程序运行时，会把具体的问题（比如“图里的伞是什么颜色的？”）填进 <code>{}</code> 里。</li>
</ul>
</li>
<li><strong>场景</strong>：<ul>
<li><strong>Pretraining (预训练)</strong>：格式比较死板，像考试填空（"Question: ... Answer: ..."）。</li>
<li><strong>SFT (指令微调)</strong>：格式更像人类自然对话，训练 AI 更有礼貌、更像真人。</li>
</ul>
</li>
</ul>
<hr />
<h3>✅ Task 4: 拆解第三类能力——认字 (OCR &amp; Doc)</h3>
<p><strong>目标</strong>：看懂 <code>OCR</code> 和 <code>DocPretraining</code>。</p>
<ul>
<li><strong>含义</strong>：OCR = Optical Character Recognition (<strong>文字识别</strong>)。即让 AI 读出图片里写的字（比如读路牌、读文档截图）。</li>
<li><strong>细分技能</strong>：<ul>
<li><strong>普通 OCR</strong>：<code>"Transcribe all the text you find."</code> (把你能找到的字都抄写下来)。</li>
<li><strong>Markdown 格式化</strong>：<code>"Convert the text from the provided image into Markdown format."</code> (把图片里的字提取出来，并且排版成 Markdown 格式)。这通常用于处理表格或文档截图。</li>
<li><strong>Grounded OCR (带定位的识别)</strong>：<code>"Recognize the text in this region: {}."</code> (识别这个区域 <code>{}</code> 里的文字)。这要求 AI 不仅能认字，还能知道字在哪里。</li>
</ul>
</li>
</ul>
<hr />
<h3>✅ Task 5: 总结与实战应用</h3>
<p><strong>目标</strong>：串联起来，理解程序是怎么用这个文件的。</p>
<p>当程序员运行训练代码时，流程是这样的：</p>
<ol>
<li><strong>准备数据</strong>：比如有一张“一只狗在草地上”的照片。</li>
<li><strong>选择任务</strong>：这次我们要训练 AI 的“看图说话”能力。</li>
<li><strong>读取文件</strong>：程序打开这个 <code>nvlm_prompts.json</code>。</li>
<li><strong>随机抽取</strong>：程序从 <code>Captioning</code> -&gt; <code>raw</code> 列表里随机抽了一句：<ul>
<li><em>这次抽到了：</em> <code>"How would you summarize the scene depicted in the picture in short?"</code></li>
</ul>
</li>
<li><strong>组合输入</strong>：程序把这张照片 + 这句提示语一起喂给 AI。</li>
<li><strong>计算误差</strong>：如果 AI 回答得不对，就修正参数。</li>
</ol>
<hr />
<h3>📝 极简总结 (Cheat Sheet)</h3>
<p>如果你以后再看这个文件，只需要记住这几个关键词的对应关系：</p>
<ul>
<li><strong>Captioning</strong> = <strong>“请描述图片”</strong>（简单描述 vs 详细描述）。</li>
<li><strong>VQA</strong> = <strong>“请回答问题”</strong>（注意 <code>{}</code> 是填问题的地方）。</li>
<li><strong>OCR / Doc</strong> = <strong>“请读出图里的字”</strong>（有的要转成 Markdown 表格，有的要找坐标）。</li>
<li><strong>Pretraining</strong> = <strong>打地基</strong>（简单、机械的指令）。</li>
<li><strong>SFT</strong> = <strong>精装修</strong>（自然、多样的对话指令）。</li>
</ul>
<p>现在回头看那些英文句子，是不是觉得它们只是在用不同的花样说同一件事？</p>