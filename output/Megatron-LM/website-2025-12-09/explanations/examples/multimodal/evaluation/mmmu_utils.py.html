<h1>examples/multimodal/evaluation/mmmu_utils.py</h1>
<p>这份代码确实比较长，涉及很多细节。但如果把它想象成<strong>一位“阅卷老师”的工作流程</strong>，就容易理解多了。</p>
<p>这个文件的核心作用是：<strong>处理多模态（MMMU）考试的数据，把题目发给AI，回收AI的答案，然后给AI打分。</strong></p>
<p>我们可以把这份代码的工作拆解成一个 <strong>5步走的 To-Do List</strong>。</p>
<hr />
<h3>📋 MMMU 阅卷老师的任务清单 (Task List)</h3>
<h4>✅ Task 1: 整理考卷 (数据准备)</h4>
<p><strong>目标</strong>：把原始的数据整理好，分清楚这是历史题还是物理题，图片在哪里。
*   <strong>代码对应部分</strong>：<code>DOMAIN_CAT2SUB_CAT</code>, <code>CAT_SHORT2LONG</code>, <code>process_single_sample</code>
*   <strong>具体步骤</strong>：
    1.  <strong>分类</strong>：定义好哪些科目属于“理科”，哪些属于“文科”（比如 <code>CAT_SHORT2LONG</code> 把 <code>phys</code> 映射为 <code>Physics</code>）。
    2.  <strong>清洗</strong>：<code>process_single_sample</code> 函数负责把一道题里的“问题”、“选项”、“图片路径”和“正确答案”提取出来，整理成一个干净的字典格式。</p>
<h4>✅ Task 2: 出题 (Prompt 构建)</h4>
<p><strong>目标</strong>：把整理好的题目变成一段话（Prompt），喂给 AI 模型，让它能看懂并在规定格式下作答。
*   <strong>代码对应部分</strong>：<code>construct_prompt</code>
*   <strong>具体步骤</strong>：
    1.  <strong>判断题型</strong>：是“选择题 (Multiple Choice)” 还是 “填空/简答题 (Open)”。
    2.  <strong>拼凑格式</strong>：
        *   如果是<strong>选择题</strong>：把选项变成 <code>(A) xxx (B) xxx</code> 的格式，并告诉模型“请选出一个字母”。
        *   如果是<strong>简答题</strong>：直接把问题放上去。
    3.  <strong>最终包装</strong>：加上一些指令（Instruction），比如“请仔细读图回答问题”，形成最终发给 AI 的 <code>final_input_prompt</code>。</p>
<h4>✅ Task 3: 审题 (解析 AI 的回答) —— <strong>这是最复杂的步骤</strong></h4>
<p><strong>目标</strong>：AI 回答的内容通常很乱（比如“我觉得答案可能是A”，“答案是3.14吧”），你需要从这些废话里提取出核心答案。
*   <strong>代码对应部分</strong>：<code>parse_multi_choice_response</code> (选择题解析), <code>parse_open_response</code> (简答题解析)
*   <strong>具体步骤</strong>：
    1.  <strong>解析选择题 (<code>parse_multi_choice_response</code>)</strong>：
        *   先找有没有 <code>(A)</code>, <code>A)</code>, <code>A.</code> 这种明确的标记。
        *   如果没找到标记，就去匹配文本内容（比如 AI 回答了“Apple”，而选项A就是Apple，那就算它选了A）。
        *   如果还是找不到，或者找到了多个，就用一些策略（比如选最后一个提到的）来决定。
    2.  <strong>解析简答题 (<code>parse_open_response</code>)</strong>：
        *   <strong>找数字</strong>：用正则表达式 (<code>extract_numbers</code>) 把答案里的数字（整数、小数、科学计数法）全扣出来。
        *   <strong>找关键词</strong>：寻找 <code>therefore</code>, <code>answer is</code> 后面的内容。
        *   <strong>标准化</strong>：把所有提取出来的东西统一格式（比如把 <code>3.14159</code> 变成 <code>3.14</code>，把大写变小写），方便后续比对。</p>
<h4>✅ Task 4: 判分 (批改作业)</h4>
<p><strong>目标</strong>：拿着提取出来的 AI 答案，跟标准答案（Ground Truth）对比，判断对错。
*   <strong>代码对应部分</strong>：<code>eval_multi_choice</code>, <code>eval_open</code>, <code>evaluate</code>
*   <strong>具体步骤</strong>：
    1.  <strong>选择题判分</strong>：非常严格，AI 选的字母必须和标准答案字母一样才算对。
    2.  <strong>简答题判分</strong>：稍微宽容一点。只要 AI 提取出的数字或关键词包含在标准答案里（或者数值足够接近），就算对。
    3.  <strong>批量批改</strong>：<code>evaluate</code> 函数会遍历所有题目，统计一共对了几道，错了几道。</p>
<h4>✅ Task 5: 填写成绩单 (生成报告)</h4>
<p><strong>目标</strong>：算出各个学科的得分率，生成最终的评测报告。
*   <strong>代码对应部分</strong>：<code>mmmu_main_eval</code>, <code>calculate_ins_level_acc</code>
*   <strong>具体步骤</strong>：
    1.  <strong>按科目归类</strong>：把所有结果按“艺术”、“生物”、“计算机”等分类。
    2.  <strong>计算准确率</strong>：用 <code>calculate_ins_level_acc</code> 算出每个大类（比如“科技与工程”）的平均分。
    3.  <strong>输出结果</strong>：打印出一个漂亮的字典，显示 <code>Overall</code>（总分）以及各个子学科的分数。</p>
<hr />
<h3>💡 总结一下</h3>
<p>这个脚本其实就是一个<strong>全自动的阅卷机器</strong>：</p>
<ol>
<li><strong>Input</strong>: 拿来考卷（原始数据）和考生的答卷（AI 的输出）。</li>
<li><strong>Process</strong>:<ul>
<li>清洗考卷。</li>
<li>费劲地去读懂考生那潦草的答案（解析）。</li>
<li>跟标准答案比对（判分）。</li>
</ul>
</li>
<li><strong>Output</strong>: 告诉你这个考生在“艺术”、“数学”、“医学”各科考了多少分，总分是多少。</li>
</ol>
<p>最后的 <code>if __name__ == '__main__':</code> 部分就是实际运行这个机器的代码：它加载了一个叫 <code>eval_results.json</code> 的文件（假设这是 AI 考完试的答题卡），然后跑一遍上面的流程，最后输出分数。</p>