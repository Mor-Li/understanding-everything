<h1>tests/test_utils/recipes/multimodal-llava.yaml</h1>
<p>这份文件其实是一个<strong>自动化测试的“菜谱”（Recipe）</strong>。</p>
<p>你可以把它想象成是写给一台超级计算机（测试服务器）看的<strong>任务清单（To-Do List）</strong>。它的核心目的是：<strong>当有程序员修改了 Megatron-LM 代码库中关于 LLaVA（一种多模态大模型）的代码时，自动运行这个脚本来检查代码有没有写挂。</strong></p>
<p>为了让你听懂，我把这份文件拆解成一个<strong>机器人的执行步骤列表</strong>：</p>
<h3>任务名称：自动测试 LLaVA 模型训练流程</h3>
<h4>第一阶段：准备工作 (Setup)</h4>
<ol>
<li>
<p><strong>[ ] 确认硬件资源</strong></p>
<ul>
<li><strong>指令来源</strong>: <code>spec</code> -&gt; <code>nodes: 1</code>, <code>gpus: 8</code>, <code>platforms: dgx_a100</code></li>
<li><strong>机器人独白</strong>: “好的，老板。给我找一台装有 8 张 A100 显卡的机器，我要开始干活了。”</li>
</ul>
</li>
<li>
<p><strong>[ ] 准备代码环境 (Script Setup)</strong></p>
<ul>
<li><strong>指令来源</strong>: <code>script_setup</code> 部分</li>
<li><strong>Todo 2.1</strong>: 配置网络和权限（登录 gitlab）。</li>
<li><strong>Todo 2.2</strong>: <strong>下载最新代码</strong>。进入 <code>/opt/megatron-lm</code>，把程序员刚刚提交的修改（Merge Request）拉取下来。</li>
<li><strong>Todo 2.3</strong>: <strong>下载参照组代码</strong>。进入 <code>/opt/megatron-lm-legacy</code>，拉取一个旧的、稳定的版本。</li>
<li><strong>Todo 2.4</strong>: <em>移花接木</em>。把新代码里的核心库 <code>megatron</code> 复制到旧代码目录里。（这一步通常是为了测试核心库在新旧环境下的兼容性，或者使用旧的框架跑新的核心逻辑）。</li>
</ul>
</li>
</ol>
<h4>第二阶段：配置参数 (Configuration)</h4>
<ol>
<li><strong>[ ] 设定运行参数 (Script - ARGUMENTS)</strong><ul>
<li><strong>指令来源</strong>: <code>script</code> -&gt; <code>ARGUMENTS</code> 数组</li>
<li><strong>机器人独白</strong>: “在跑模型之前，我得先把参数填好。”</li>
<li><strong>关键参数</strong>:<ul>
<li><code>TRAINING_SCRIPT_PATH</code>: 告诉机器要去跑 <code>pretrain_vlm.py</code>（这是训练视觉语言模型的脚本）。</li>
<li><code>TRAINING_PARAMS_PATH</code>: 模型的具体配置文件在哪里。</li>
<li><code>GOLDEN_VALUES_PATH</code>: <strong>参考答案在哪里</strong>。这是一个存着“正确数据”的文件。跑完测试后，机器会把结果和这个文件对比，如果误差太大，测试就失败。</li>
<li><code>OUTPUT_PATH</code>: 日志和结果存哪里。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4>第三阶段：正式执行 (Execution)</h4>
<ol>
<li><strong>[ ] 运行测试脚本</strong><ul>
<li><strong>指令来源</strong>: <code>bash ./tests/functional_tests/shell_test_utils/run_ci_test.sh ...</code></li>
<li><strong>机器人独白</strong>: “参数都设好了，现在我执行 <code>run_ci_test.sh</code> 这个脚本，它会启动 LLaVA 模型的预训练过程。”</li>
</ul>
</li>
</ol>
<h4>第四阶段：变种测试 (Variations)</h4>
<ol>
<li><strong>[ ] 执行不同的测试套餐 (Products)</strong><ul>
<li><strong>指令来源</strong>: <code>products</code> 部分</li>
<li>这份文件不仅仅跑一次，它定义了<strong>两种</strong>不同的跑法（Test Cases），机器需要分别完成：</li>
<li><strong>套餐 A (Task 1)</strong>: <code>multimodal_llava_mcore_te_tp1_pp1</code><ul>
<li><strong>含义</strong>: 在 H100 显卡上，用 Tensor Parallel=1, Pipeline Parallel=1 的简单配置跑。</li>
</ul>
</li>
<li><strong>套餐 B (Task 2)</strong>: <code>multimodal_llava_mcore_te_tp4_sp_cp2</code><ul>
<li><strong>含义</strong>: 在 H100 显卡上，上强度！用 Tensor Parallel=4 (张量并行), Context Parallel=2 (上下文并行) 的复杂配置跑。</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr />
<h3>总结：文中的核心观点</h3>
<p>如果把这个文件看作一个人在说话，他的观点是：</p>
<ol>
<li><strong>“我不信任程序员”</strong>：每次有人改代码，我都要在一个干净的环境里（Setup阶段）重新拉取代码。</li>
<li><strong>“多模态模型很复杂，必须分情况测”</strong>：不能只测一种配置，我要测简单的单卡/少卡模式（TP1），也要测复杂的并行模式（TP4/CP2），确保并行训练功能是正常的。</li>
<li><strong>“结果要有标准”</strong>：通过 <code>GOLDEN_VALUES_PATH</code>，说明测试不是跑通就行，关键指标（比如 Loss 损失值）必须和标准答案对得上，否则就是 Bug。</li>
</ol>
<p><strong>一句话概括：</strong>
这是一个<strong>自动化测试配置文件</strong>，用于在 NVIDIA 的高性能服务器上，验证 <strong>LLaVA 多模态大模型</strong>在不同并行策略（TP、PP、CP）下的训练代码是否正确。</p>