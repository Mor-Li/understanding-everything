<h1>tests/test_utils/recipes/moe-static-inference.yaml</h1>
<p>这个文件其实是一个 <strong>自动化测试脚本的“菜谱”（Recipe）</strong>。</p>
<p>你可以把它想象成给一台超级计算机（测试服务器）下达的一张 <strong>“任务清单” (To-Do List)</strong>。这张清单告诉计算机：去哪里下载代码、用什么样的机器、跑什么测试、以及怎么判断测试是通过了还是失败了。</p>
<p>具体来说，这是为了测试 <strong>MoE (Mixture of Experts，混合专家模型)</strong> 在 <strong>静态推理 (Static Inference)</strong> 场景下是否正常工作。</p>
<p>为了让你更容易理解，我把你当作那台计算机，把这个文件拆解成你需要执行的 <strong>5个步骤的任务清单</strong>：</p>
<hr />
<h3>📋 任务清单：MoE 静态推理测试</h3>
<h4>任务 1：准备硬件环境 (Spec &amp; Resources)</h4>
<ul>
<li><strong>指令来源</strong>: <code>spec</code> 部分</li>
<li><strong>你需要做什么</strong>:<ul>
<li>申请 <strong>1台</strong> 服务器节点 (<code>nodes: 1</code>)。</li>
<li>确保这台机器上有 <strong>8张显卡</strong> (<code>gpus: 8</code>)。</li>
<li>默认机器类型是 <strong>DGX A100</strong>，但后面具体的测试用例可能会升级成 <strong>H100</strong>。</li>
<li>准备好 Python 环境 (<code>mcore-pyt-{environment}</code>).</li>
</ul>
</li>
</ul>
<h4>任务 2：下载与配置代码 (Script Setup)</h4>
<ul>
<li><strong>指令来源</strong>: <code>script_setup</code> 部分</li>
<li><strong>你需要做什么</strong>:<ol>
<li><strong>登录</strong>: 登录到 NVIDIA 的内部 GitLab 服务器。</li>
<li><strong>下载新代码</strong>: 进入 <code>/opt</code> 目录，下载当前的 <code>megatron-lm</code> 代码库（这就是我们要测试的对象），并切换到指定的提交版本（Commit）。</li>
<li><strong>下载旧代码</strong>: 下载一个 <code>megatron-lm-legacy</code>（旧版/基准版）代码库。</li>
<li><strong>“移花接木”</strong>: 把新代码里的 <code>megatron</code> 核心文件夹复制到旧代码库里。</li>
<li><strong>目的</strong>: 这通常是为了在一个稳定的旧环境中测试新核心代码的功能，或者是为了对比测试。</li>
</ol>
</li>
</ul>
<h4>任务 3：配置测试参数 (Script - Arguments)</h4>
<ul>
<li><strong>指令来源</strong>: <code>script</code> 中的 <code>ARGUMENTS</code> 数组</li>
<li><strong>你需要做什么</strong>:<ul>
<li>设置一系列环境变量，告诉程序：<ul>
<li><strong>模型在哪？</strong> (<code>CHECKPOINT_LOAD_PATH</code>)</li>
<li><strong>跑哪个脚本？</strong> (<code>gpt_static_inference.py</code>，即 GPT 模型的静态推理脚本)。</li>
<li><strong>配置文件在哪？</strong> (<code>model_config.yaml</code>)。</li>
<li><strong>标准答案在哪？</strong> (<code>GOLDEN_VALUES_PATH</code>)。测试跑完后，输出的数值必须和这个文件里的“金标准”数值一致，才算通过。</li>
<li><strong>结果存哪？</strong> (<code>OUTPUT_PATH</code>)。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4>任务 4：执行测试命令 (Run Command)</h4>
<ul>
<li><strong>指令来源</strong>: <code>script</code> 的最后一行</li>
<li><strong>你需要做什么</strong>:<ul>
<li>运行 <code>bash ./tests/functional_tests/shell_test_utils/run_ci_test.sh ...</code></li>
<li>这就相当于按下了“启动”按钮，开始真正跑模型推理了。</li>
</ul>
</li>
</ul>
<h4>任务 5：执行具体的测试变体 (Products)</h4>
<ul>
<li><strong>指令来源</strong>: <code>products</code> 部分</li>
<li>
<p><strong>你需要做什么</strong>:</p>
<ul>
<li>
<p>上面是通用的步骤，这里列出了 <strong>3个具体的考试题目</strong>。你需要分别跑这三种情况：</p>
</li>
<li>
<p><strong>题目 A (基础测试):</strong></p>
<ul>
<li><strong>名字</strong>: <code>gpt_static_inference_tp1_pp1_ep1_16B_logitsmatch</code></li>
<li><strong>含义</strong>: 跑一个 16B 大小的模型。</li>
<li><strong>并行策略</strong>: TP1 (张量并行=1), PP1 (流水线并行=1), EP1 (专家并行=1)。也就是<strong>不切分模型</strong>，单卡或简单模式运行。</li>
<li><strong>硬件</strong>: 在 <strong>DGX H100</strong> 上跑。</li>
</ul>
</li>
<li>
<p><strong>题目 B (分布式测试):</strong></p>
<ul>
<li><strong>名字</strong>: <code>gpt_static_inference_tp4_pp1_ep4_16B_logitsmatch</code></li>
<li><strong>含义</strong>: 同样的模型，但要切分。</li>
<li><strong>并行策略</strong>: <strong>TP4</strong> (模型切成4份), <strong>EP4</strong> (专家层切成4份)。这是为了测试多卡并行推理是否正确。</li>
<li><strong>硬件</strong>: <strong>DGX H100</strong>。</li>
</ul>
</li>
<li>
<p><strong>题目 C (性能优化测试 - 目前标记为坏的):</strong></p>
<ul>
<li><strong>名字</strong>: <code>gpt_static_inference_cuda_graphs_pad_tp4_pp1_ep4_16B_logitsmatch</code></li>
<li><strong>含义</strong>: 和题目 B 一样，但开启了 <strong>CUDA Graphs</strong>（一种加速技术）。</li>
<li><strong>状态</strong>: <code>scope: [mr-broken]</code>。说明这个测试目前是坏的（Broken），可能已知有问题，暂时不作为必须要通过的标准，或者正在修复中。</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr />
<h3>💡 总结：这篇文章到底在讲啥？</h3>
<p>这就好比你在一家汽车工厂：
1.  <strong>文件</strong>就是一张<strong>质检单</strong>。
2.  <strong>任务</strong>是：把刚生产出来的引擎（新代码）装到车上。
3.  <strong>测试</strong>是：把车开出去跑一圈（Inference）。
4.  <strong>标准</strong>是：跑出来的速度和油耗必须和说明书（Golden Values）完全一致。
5.  <strong>变体</strong>是：既要测普通模式（题目A），也要测四驱模式（题目B），还要测运动模式（题目C）。</p>
<p>如果这些测试都通过了（Logits Match，输出数值匹配），说明你写的这段 MoE 模型推理代码是没问题的，可以合并进主分支。</p>