<h1>tests/test_utils/recipes/gpt-dynamic-inference.yaml</h1>
<p>这份文件实际上是一个 <strong>自动化测试流程的“食谱”（Recipe）</strong>。</p>
<p>把它想象成你给一个机器人（测试服务器）下达的一张 <strong>任务清单（ToDo List）</strong>。机器人的任务是：<strong>测试 Megatron-LM（一个大模型训练框架）的 GPT 模型在“动态推理”功能上是否正常</strong>。</p>
<p>为了让你更容易理解，我把这份文件拆解成一个机器人需要执行的 <strong>5个步骤的任务清单</strong>：</p>
<hr />
<h3>✅ 任务清单：GPT 动态推理测试流程</h3>
<h4>任务 1：自我介绍与环境确认 (Metadata)</h4>
<p><strong>机器人的内心独白</strong>：“首先，我要确认我是谁，我要测什么。”
*   <strong>我是谁</strong>：一个基础测试任务 (<code>type: basic</code>)。
*   <strong>负责人</strong>：mcore 团队 (<code>maintainers: [mcore]</code>)。
*   <strong>我要测的模型</strong>：GPT (<code>model: gpt</code>)。
*   <strong>我的硬件环境</strong>：需要 1 个节点，1 张 GPU (<code>nodes: 1</code>, <code>gpus: 1</code>)，通常在 DGX A100 机器上跑 (<code>platforms: dgx_a100</code>)。</p>
<h4>任务 2：准备代码仓库 (script_setup)</h4>
<p><strong>机器人的内心独白</strong>：“在开始测试前，我得先把代码下载下来，还要搞定新旧代码的替换。”
1.  <strong>登录</strong>：登录 NVIDIA 的内部 GitLab。
2.  <strong>下载新代码</strong>：
    *   进入 <code>/opt/megatron-lm</code> 目录。
    *   下载当前正在开发的最新代码（也就是本次要测试的代码提交 <code>MCORE_MR_COMMIT</code>）。
3.  <strong>下载旧代码（作为基准/参考）</strong>：
    *   进入 <code>/opt/megatron-lm-legacy</code> 目录。
    *   下载之前的旧版本代码。
4.  <strong>移花接木（关键步骤）</strong>：
    *   <code>rm -rf megatron; cp -a /opt/megatron-lm/megatron ./</code>
    *   <strong>含义</strong>：把<strong>新代码</strong>里的核心库（megatron文件夹）复制到<strong>旧代码</strong>的目录里。这通常是为了测试新写的核心库是否兼容旧的运行环境，或者在旧的框架下运行新的逻辑。</p>
<h4>任务 3：配置测试参数 (ARGUMENTS)</h4>
<p><strong>机器人的内心独白</strong>：“代码准备好了，现在我要准备运行脚本需要的‘原材料’（参数）。”
机器人整理了一份参数表 <code>ARGUMENTS</code>：
*   <strong>模型权重在哪？</strong> <code>/mnt/artifacts</code> (CHECKPOINT_LOAD_PATH)
*   <strong>数据在哪？</strong> <code>/workspace/data/cache</code> (DATA_CACHE_PATH)
*   <strong>运行哪个脚本？</strong> <code>examples/inference/gpt/gpt_dynamic_inference.py</code> (这是本次测试的主角：GPT动态推理脚本)。
*   <strong>标准答案在哪？</strong> <code>golden_values_...json</code> (这是“金标准”，如果跑出来的结果和这个文件不一样，测试就失败)。
*   <strong>要开启轻量模式吗？</strong> <code>ENABLE_LIGHTWEIGHT_MODE</code> (由外部变量决定)。</p>
<h4>任务 4：执行测试并阅卷 (script)</h4>
<p><strong>机器人的内心独白</strong>：“一切就绪，开始跑测试脚本，并对比结果。”
*   <strong>执行命令</strong>：<code>bash ./tests/functional_tests/shell_test_utils/run_ci_test.sh</code>
*   <strong>动作</strong>：
    1.  加载上面的参数。
    2.  运行 GPT 推理程序。
    3.  程序会生成一些文本或数据（Logits）。
    4.  <strong>自动阅卷</strong>：脚本会自动把生成的结果与“标准答案”（Golden Values）进行比对。如果一致，测试通过；如果不一致，报错。</p>
<h4>任务 5：根据不同口味上菜 (products)</h4>
<p><strong>机器人的内心独白</strong>：“刚才那是通用流程，实际上我有好几种不同的‘套餐’要测。”
文件底部的 <code>products</code> 定义了具体的测试变种。机器人会根据不同的配置多次执行上述流程：</p>
<ul>
<li>
<p><strong>套餐 A (基础测试)</strong>：</p>
<ul>
<li><strong>名字</strong>：<code>gpt_dynamic_inference_tp1_pp1_583m_logitsmatch</code></li>
<li><strong>配置</strong>：5.83亿参数的模型，1张卡（TP1），不切分流水线（PP1）。</li>
<li><strong>状态</strong>：标为 <code>mr-broken</code>，说明这个测试目前在 GitHub CI 上跑不通或者被禁用了。</li>
</ul>
</li>
<li>
<p><strong>套餐 B (并行测试)</strong>：</p>
<ul>
<li><strong>名字</strong>：<code>gpt_dynamic_inference_tp8_pp1_583m_logitsmatch</code></li>
<li><strong>配置</strong>：同样的模型，但是用 <strong>8张卡并行</strong>（TP8）来跑。这是为了测试多卡并行推理是否正常。</li>
<li><strong>硬件</strong>：指定在 H100 机器上跑。</li>
</ul>
</li>
<li>
<p><strong>套餐 C (黑科技测试 - FP8)</strong>：</p>
<ul>
<li><strong>名字</strong>：<code>...cuda_graphs_fp8_logitsmatch</code></li>
<li><strong>配置</strong>：开启 <strong>FP8</strong>（8位浮点数，速度更快但精度低一点）和 <strong>CUDA Graphs</strong>（一种加速技术）。测试这些加速功能开启后，结果是否依然正确。</li>
</ul>
</li>
<li>
<p><strong>套餐 D (解码图测试)</strong>：</p>
<ul>
<li><strong>名字</strong>：<code>...decode_graphs_only</code></li>
<li><strong>配置</strong>：专门测试 <code>decode</code> 阶段的 CUDA Graphs 优化。</li>
</ul>
</li>
</ul>
<hr />
<h3>总结：这文件到底是干啥的？</h3>
<p>这就好比你写了一个自动阅卷脚本：
1.  <strong>准备阶段</strong>：把考生的试卷（新代码）拿来。
2.  <strong>设置考场</strong>：指定用哪支笔、哪张纸（参数设置）。
3.  <strong>考试内容</strong>：让考生做几套不同难度的卷子（单卡推理、8卡并行推理、FP8加速推理）。
4.  <strong>判分</strong>：把考生的答案和标准答案（Golden Values）对比，全对才算过。</p>