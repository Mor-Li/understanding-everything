<h1>tests/test_utils/recipes/mimo.yaml</h1>
<p>这个文件 <code>mimo.yaml</code> 其实是一个<strong>自动化测试的“菜谱”（Recipe）</strong>。</p>
<p>想象你是一个负责测试 AI 模型的总管，这个文件就是你写给机器人的<strong>任务清单</strong>。它的核心目的是：<strong>在英伟达的高端显卡（H100）上，自动下载代码、准备数据，并运行一个叫 MIMO 的多模态模型的训练测试。</strong></p>
<p>为了让你看懂，我把这个文件拆解成一个 <strong>5步走的 Task List（任务清单）</strong>，带你一步步看它是怎么工作的：</p>
<hr />
<h3>Task 1: 准备基础设施 (Spec &amp; Hardware)</h3>
<p><strong>目标</strong>：告诉测试系统，我们需要什么样的电脑和硬件来干活。</p>
<ul>
<li><strong>原文对应</strong>：
    <code>yaml
    spec:
      model: mimo
      nodes: 1
      gpus: 8
      platforms: dgx_h100</code></li>
<li><strong>解读</strong>：<ol>
<li><strong>我要测啥？</strong> 测 <code>mimo</code> 模型（这是一个多模态大模型）。</li>
<li><strong>我要多少资源？</strong> 给我开 <code>1</code> 台机器，但这台机器上要有 <code>8</code> 张显卡。</li>
<li><strong>我要什么卡？</strong> 必须是 <code>dgx_h100</code>（目前最顶级的 AI 算力平台）。</li>
</ol>
</li>
</ul>
<hr />
<h3>Task 2: 准备“食材” (Artifacts)</h3>
<p><strong>目标</strong>：做饭得有米有菜。训练模型需要预训练权重（模型底座）和数据集。</p>
<ul>
<li><strong>原文对应</strong>：
    <code>yaml
    artifacts:
      /workspace/data/llava_pretrain_energon: mixed/mcore_mimo_vlm/llava_pretrain_energon
      /mnt/artifacts/model/vicuna_7b_pyt/dcp/mcore-v1.5_fp32: model/vicuna_7b_pyt/dcp/mcore-v1.5_fp32</code></li>
<li><strong>解读</strong>：<ul>
<li>这里做了一个<strong>文件映射</strong>。冒号右边是仓库里的原始数据，左边是机器上能看到的路径。</li>
<li><strong>食材1</strong>：<code>llava_pretrain_energon</code>（这是训练用的图片/文本数据）。</li>
<li><strong>食材2</strong>：<code>vicuna_7b</code>（这是基础语言模型 Vicuna 7B 的权重文件，MIMO 模型应该是基于这个微调的）。</li>
</ul>
</li>
</ul>
<hr />
<h3>Task 3: 清理厨房并下载代码 (Script Setup)</h3>
<p><strong>目标</strong>：在开始跑测试前，先把环境配置好，把最新的代码拉下来。</p>
<ul>
<li><strong>原文对应</strong> (<code>script_setup</code> 部分)：
    <code>yaml
    unset https_proxy
    # ... 登录 gitlab ...
    # Checkout latest (下载最新代码)
    cd /opt/megatron-lm
    git fetch origin $MCORE_MR_COMMIT
    # ...
    # Checkout backwards-ref (下载旧版本代码作为参考/依赖)
    cd /opt/megatron-lm-legacy
    # ...</code></li>
<li><strong>解读</strong>：<ol>
<li><strong>登录</strong>：配置 Git 权限。</li>
<li><strong>下载最新版</strong>：去 <code>megatron-lm</code> 目录，拉取当前正在开发的最新代码（MR Commit）。</li>
<li><strong>准备旧版本</strong>：去 <code>megatron-lm-legacy</code> 目录，拉取一个旧的稳定版本。这通常是为了做兼容性测试，或者某些组件依赖旧的结构。</li>
</ol>
</li>
</ul>
<hr />
<h3>Task 4: 开始“烹饪” (Script)</h3>
<p><strong>目标</strong>：这是核心步骤。组装命令，真正运行训练脚本。</p>
<ul>
<li><strong>原文对应</strong> (<code>script</code> 部分)：
    <code>yaml
    NAME=$(echo {test_case}_{environment} | sed 's/dgx_h100/dgx_a100/g')
    ARGUMENTS=(
        "DATA_PATH=/mnt/artifacts"
        "TRAINING_SCRIPT_PATH=./examples/mimo/train.py"
        "TRAINING_PARAMS_PATH=.../model_config.yaml"
        "GOLDEN_VALUES_PATH=.../golden_values....json"
        ...
    )
    bash ./tests/functional_tests/shell_test_utils/run_ci_test.sh ${{ARGUMENTS[@]}}</code></li>
<li><strong>解读</strong>：<ol>
<li><strong>设置变量</strong>：定义数据在哪里 (<code>DATA_PATH</code>)，结果存哪里 (<code>OUTPUT_PATH</code>)。</li>
<li><strong>指定主厨</strong>：指定要运行的 Python 脚本是 <code>./examples/mimo/train.py</code>。</li>
<li><strong>指定菜谱细节</strong>：指定参数配置文件 (<code>model_config.yaml</code>)。</li>
<li><strong>指定评分标准</strong>：<code>GOLDEN_VALUES_PATH</code> 指向一个 JSON 文件，里面存着“标准答案”（比如 Loss 应该降到多少）。如果跑出来的结果和这个不一样，测试就失败。</li>
<li><strong>一键启动</strong>：最后运行 <code>run_ci_test.sh</code>，把上面定义的参数全传进去。</li>
</ol>
</li>
</ul>
<hr />
<h3>Task 5: 确认“菜单” (Products)</h3>
<p><strong>目标</strong>：定义具体要跑哪几个具体的测试案例。</p>
<ul>
<li><strong>原文对应</strong>：
    ```yaml
    products:<ul>
<li>test_case: [mimo_vlm_pretrain_convergence_tp1_pp1_cp1_dp8]
    products:<ul>
<li>environment: [dev]
    scope: [flaky]
```</li>
</ul>
</li>
</ul>
</li>
<li><strong>解读</strong>：<ul>
<li><strong>测试案例名</strong>：<code>mimo_vlm_pretrain_convergence_tp1_pp1_cp1_dp8</code>。<ul>
<li>这名字很长，但含义很深：</li>
<li><code>mimo_vlm</code>: 测的是 MIMO 视觉语言模型。</li>
<li><code>pretrain</code>: 测的是预训练阶段。</li>
<li><code>convergence</code>: 测的是收敛性（看 Loss 下不下降）。</li>
<li><code>tp1_pp1_cp1_dp8</code>: 这是并行策略（Tensor并行1，流水线并行1，Context并行1，<strong>数据并行8</strong>）。这意味着8张卡每张卡跑一份数据副本。</li>
</ul>
</li>
<li><strong>环境</strong>：<code>dev</code>（开发环境）。</li>
<li><strong>标签</strong>：<code>flaky</code>（这意味着这个测试可能不太稳定，偶尔挂了也不一定全是代码的锅）。</li>
</ul>
</li>
</ul>
<hr />
<h3>总结</h3>
<p>这篇文档就是在说：</p>
<blockquote>
<p>“嘿，CI系统！请给我分配 <strong>8张 H100 显卡</strong>，挂载上 <strong>Vicuna 和 LLaVA 的数据</strong>。先帮我把 <strong>Megatron-LM 的最新代码</strong>拉下来。然后，按照 <code>model_config.yaml</code> 里的参数，跑一下 <code>mimo/train.py</code> 训练脚本。</p>
<p>具体的测试场景是：<strong>8卡数据并行预训练</strong>。跑完之后，去对比一下 <code>golden_values</code>，看看 Loss 对不对。”</p>
</blockquote>