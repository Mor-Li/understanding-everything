<h1>tests/test_utils/recipes/mamba.yaml</h1>
<p>这份文件其实就是一个 <strong>“自动化测试的菜谱（Recipe）”</strong>。</p>
<p>在软件开发（特别是像 Megatron-LM 这种大型AI模型框架）中，每次改代码都需要测试。手动测试太慢，所以工程师写了这个 YAML 文件，告诉测试服务器（CI 系统）该怎么做。</p>
<p>你可以把这个文件想象成给机器人的<strong>指令清单</strong>。为了让你看懂，我把它拆解成 5 个 Task（任务），我们一步步来完成。</p>
<hr />
<h3>📋 任务清单 (Task List)</h3>
<h4>✅ Task 1: 搞清楚“我是谁，我要干什么” (文件元数据)</h4>
<p><strong>目标：</strong> 理解文件的基本属性。
*   <strong>代码位置：</strong> <code>type: basic</code>, <code>maintainers: [mcore]</code>
*   <strong>解读：</strong> 这是一份基础类型的测试配置，维护者是 <code>mcore</code> 团队。
*   <strong>核心观点：</strong> 这个文件的目的是为了测试 <strong>Mamba</strong> 模型（一种新的AI模型架构），这一点从文件名 <code>mamba.yaml</code> 和后面的脚本内容可以看出来。</p>
<h4>✅ Task 2: 准备“厨房和厨具” (Spec 配置)</h4>
<p><strong>目标：</strong> 弄清楚测试需要什么样的硬件环境。
*   <strong>代码位置：</strong> <code>spec</code> 部分
    *   <code>nodes: 1</code>, <code>gpus: 8</code>: 需要 1 台机器，8 张显卡。
    *   <code>platforms: dgx_a100</code>: 指定要用 NVIDIA DGX A100 这种高性能服务器。
    *   <code>n_repeat: 5</code>: 这个测试要重复跑 5 次，确保结果稳定，不是运气好。
*   <strong>核心观点：</strong> 这是一个<strong>高算力需求</strong>的测试，不是在普通电脑上跑的，是用来测试大规模模型训练的。</p>
<h4>✅ Task 3: 准备“食材” (Script Setup)</h4>
<p><strong>目标：</strong> 下载代码，配置环境。
*   <strong>代码位置：</strong> <code>script_setup</code> 部分
*   <strong>解读：</strong>
    1.  <strong>登录：</strong> <code>echo "machine..."</code> 登录内部的代码仓库。
    2.  <strong>下载最新代码：</strong> <code>git fetch origin $MCORE_MR_COMMIT</code>。这是把开发者刚修改好的代码（Merge Request）拉下来。
    3.  <strong>下载旧代码（对照组）：</strong> 下面那段 <code>Checkout backwards-ref</code> 是下载一个旧版本的代码，通常是为了做兼容性对比，或者借用旧版的一些工具。
*   <strong>核心观点：</strong> 测试前必须确保拿到的是<strong>最新提交的、待测试的代码</strong>，并且环境要干净（<code>rm -rf</code> 删除了旧目录）。</p>
<h4>✅ Task 4: 开始“烹饪” (Script 执行)</h4>
<p><strong>目标：</strong> 真正运行测试命令。
*   <strong>代码位置：</strong> <code>script</code> 部分
*   <strong>解读：</strong> 这里定义了一堆变量（ARGUMENTS），然后运行了一个脚本 <code>run_ci_test.sh</code>。
    *   <code>TRAINING_SCRIPT_PATH=pretrain_mamba.py</code>: <strong>重点！</strong> 这里明确了是在跑 Mamba 模型的预训练脚本。
    *   <code>CHECKPOINT_...</code>: 设置模型存档（Checkpoint）的保存和读取路径。
    *   <code>GOLDEN_VALUES_PATH</code>: 设置“标准答案”的路径。测试跑完后，会把结果和这个“金标准”对比，看看有没有跑歪。
*   <strong>核心观点：</strong> 这是测试的核心逻辑——<strong>配置好路径参数，运行 Mamba 预训练脚本，并准备好与标准结果进行比对。</strong></p>
<h4>✅ Task 5: 制定“套餐菜单” (Products 测试矩阵)</h4>
<p><strong>目标：</strong> 决定要在哪些具体场景下测试。
*   <strong>代码位置：</strong> <code>products</code> 部分
*   <strong>解读：</strong> 这里列出了具体的<strong>测试用例（Test Cases）</strong>。
    *   例如：<code>hybrid_mr_mcore_te_tp1_pp1_cp1...</code> 这一长串名字代表一种并行策略的组合：
        *   <code>tp1</code>: Tensor Parallel = 1 (张量并行)
        *   <code>pp1</code>: Pipeline Parallel = 1 (流水线并行)
        *   <code>cp1</code>: Context Parallel = 1 (上下文并行)
    *   下面还有 <code>tp2_pp1</code> 等不同组合。
    *   <code>platforms: [dgx_h100]</code>: 注意这里，虽然上面默认是 A100，但这里指定这几个测试要在更强的 <strong>H100</strong> 显卡上跑。
*   <strong>核心观点：</strong> 同一份代码，要在<strong>不同的并行配置</strong>（TP/PP/CP的不同组合）和<strong>不同的硬件</strong>（H100）上都跑通，才算测试通过。</p>
<hr />
<h3>💡 总结 (Summary)</h3>
<p>如果用一句话概括这个文件讲了什么：</p>
<blockquote>
<p><strong>“这是一个给 CI 服务器的指令，要求它在 NVIDIA DGX 服务器上，拉取最新的代码，针对不同的并行策略组合（TP/PP/CP），运行 Mamba 模型的预训练任务，并检查结果是否正确。”</strong></p>
</blockquote>