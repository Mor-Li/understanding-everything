<h1>tests/test_utils/recipes/mamba-dynamic-inference.yaml</h1>
<p>这份文件实际上是一个<strong>自动化测试的“菜谱”（Recipe）</strong>。</p>
<p>在大型软件开发（比如 NVIDIA 开发 Megatron-LM 这种大模型训练框架）中，每次修改代码，都需要机器自动运行一遍测试，确保新写的代码没把旧功能搞坏。</p>
<p>你可以把这个文件看作是写给<strong>测试机器人</strong>的一张<strong>任务清单（ToDo List）</strong>。</p>
<p>下面我按照机器人执行任务的顺序，一步一步为你拆解这张清单：</p>
<h3>任务清单：测试机器人执行步骤</h3>
<h4>Step 1: 确认身份与基础配置 (Metadata &amp; Spec)</h4>
<p><strong>机器人独白：</strong> “我先看看这次任务的基本要求是什么。”</p>
<ul>
<li><strong>我是谁：</strong> <code>type: basic</code>，这是一个基础测试任务。</li>
<li><strong>负责人：</strong> <code>maintainers: [mcore]</code>，有问题找 mcore 团队。</li>
<li><strong>我要测试什么模型：</strong> <code>model: hybrid</code>。这里的 Hybrid 通常指混合架构模型（比如 Mamba + Transformer 混合）。</li>
<li><strong>我需要什么硬件：</strong><ul>
<li><code>nodes: 1</code>, <code>gpus: 1</code>：给我一台机器，一张显卡。</li>
<li><code>platforms: dgx_a100</code>：默认给我用 A100 显卡（但在文件末尾会被覆盖成 H100）。</li>
</ul>
</li>
</ul>
<h4>Step 2: 准备代码环境 (Script Setup)</h4>
<p><strong>机器人独白：</strong> “硬件有了，我现在要去下载代码。这步最关键，我要准备两份代码来做对比。”</p>
<p>这一段 <code>script_setup</code> 是在做准备工作：
1.  <strong>配置权限：</strong> 登录 NVIDIA 的内部 GitLab，获取下载权限。
2.  <strong>下载最新代码 (Current)：</strong>
    *   进入 <code>/opt/megatron-lm</code> 目录。
    *   下载当前开发者提交的最新代码（<code>$MCORE_MR_COMMIT</code>）。这是<strong>我们要测试的对象</strong>。
3.  <strong>下载旧代码 (Legacy/Backwards)：</strong>
    *   进入 <code>/opt/megatron-lm-legacy</code> 目录。
    *   下载一个已知的、稳定的旧版本代码（<code>$MCORE_BACKWARDS_COMMIT</code>）。
    *   <em>注意：</em> 它把新代码里的 <code>megatron</code> 核心库复制到了旧代码文件夹里。这通常是为了测试<strong>新核心代码能否兼容旧的外部接口</strong>。</p>
<h4>Step 3: 准备测试参数 (Script - Arguments)</h4>
<p><strong>机器人独白：</strong> “代码下好了，现在我要准备运行测试的具体参数，就像做菜准备调料。”</p>
<p>这一段 <code>script</code> 定义了一个叫 <code>ARGUMENTS</code> 的大列表，告诉程序怎么跑：
*   <strong>模型权重在哪？</strong> <code>CHECKPOINT_LOAD_PATH</code>（从哪里加载训练好的模型）。
*   <strong>运行哪个脚本？</strong> <code>TRAINING_SCRIPT_PATH=examples/inference/gpt/gpt_dynamic_inference.py</code>。
    *   <strong>重点：</strong> 虽然文件名叫 <code>training</code>，但这里跑的是 <code>inference</code>（推理）。也就是让模型生成一段话，看看对不对。
*   <strong>模型长啥样？</strong> <code>TRAINING_PARAMS_PATH</code>（读取具体的模型配置文件）。
*   <strong>标准答案在哪？</strong> <code>GOLDEN_VALUES_PATH</code>。
    *   <strong>核心逻辑：</strong> 自动化测试需要一个“标准答案”（Golden Values）。机器人跑完推理后，会把生成的结果和这个文件里的数值对比。如果一致，测试通过；如果不一致，报错。
*   <strong>结果存哪？</strong> <code>OUTPUT_PATH</code> 和 <code>TENSORBOARD_PATH</code>。</p>
<h4>Step 4: 执行测试命令 (Run Command)</h4>
<p><strong>机器人独白：</strong> “一切准备就绪，开始点火发射！”</p>
<ul>
<li><code>bash ./tests/functional_tests/shell_test_utils/run_ci_test.sh ${{ARGUMENTS[@]}}</code></li>
<li>机器人调用一个通用的 Shell 脚本 <code>run_ci_test.sh</code>，并把上面 Step 3 准备好的那一堆参数传进去。这个脚本会启动 Python 程序，加载模型，进行推理，并对比结果。</li>
</ul>
<h4>Step 5: 定义具体考题 (Products)</h4>
<p><strong>机器人独白：</strong> “上面的规则是通用的，具体今天要考哪道题呢？”</p>
<p>文件最后的 <code>products</code> 部分定义了具体的测试案例：
*   <strong>考题名称：</strong> <code>test_case: [hybrid_dynamic_inference_tp1_pp1_dp8_583m]</code>
    *   这串字符含义丰富：
    *   <code>hybrid</code>: 混合架构（Mamba）。
    *   <code>dynamic_inference</code>: 动态推理测试。
    *   <code>tp1_pp1_dp8</code>: 并行策略（Tensor并行1，流水线并行1，数据并行8）。
    *   <code>583m</code>: 模型大小是 5.83 亿参数。
*   <strong>运行环境：</strong> <code>environment: [dev]</code>（开发环境）。
*   <strong>特定硬件：</strong> <code>platforms: [dgx_h100]</code>。
    *   这里指明了这道题必须在 <strong>H100</strong> 显卡上跑（覆盖了 Step 1 里的 A100）。</p>
<hr />
<h3>总结：这文件到底是干嘛的？</h3>
<p>简单来说，这个文件告诉 CI 系统：</p>
<blockquote>
<p><strong>“请帮我在 H100 显卡上，拉取最新的代码，运行一个 5.83亿参数的 Mamba 混合模型的推理测试。请读取指定的配置文件，并将推理结果与标准答案（Golden Values）进行对比，看看新代码有没有把推理功能搞坏。”</strong></p>
</blockquote>