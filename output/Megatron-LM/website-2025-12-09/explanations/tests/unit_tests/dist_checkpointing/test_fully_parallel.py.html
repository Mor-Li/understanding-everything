<h1>tests/unit_tests/dist_checkpointing/test_fully_parallel.py</h1>
<p>完全理解你的困惑。这段代码涉及的是 <strong>分布式深度学习框架（Megatron-LM）中“检查点（Checkpoint）”保存与加载的核心逻辑测试</strong>。</p>
<p>如果不了解分布式训练的背景，看这些代码确实像天书。</p>
<p>为了让你读懂，我制定了一个 <strong>“从概念到代码”的学习 Task List</strong>。我们把这个文件拆解成 6 个步骤，像剥洋葱一样一步步看懂它在干什么。</p>
<hr />
<h3>🟢 Task 1：理解背景（我们在解决什么问题？）</h3>
<p>在看代码前，先建立这个概念：
*   <strong>场景</strong>：假设你在 8 张显卡（GPU）上训练一个巨大的模型。
*   <strong>问题</strong>：训练到一半要存盘（Save Checkpoint）。
    *   <em>笨办法 A</em>：每张卡都把自己显存里的数据存成一个文件。结果：文件太多，且很多数据是重复的（比如数据并行 DP 模式下，不同卡的模型参数其实是一样的）。
    *   <em>笨办法 B</em>：所有卡把数据发给 0 号卡，由 0 号卡统一存。结果：0 号卡内存爆炸，存盘极慢。
*   <strong>本代码测试的策略（Fully Parallel Strategy）</strong>：
    *   <strong>智能分工</strong>：大家商量一下，“你存 Tensor A，我存 Tensor B，他存 Tensor C”。
    *   <strong>去重</strong>：如果 Rank 0 和 Rank 1 的数据一样，只让一个人存。
    *   <strong>负载均衡</strong>：不要让某一张卡累死，大家干的活要差不多。</p>
<p><strong>结论</strong>：这个文件的目的，就是<strong>测试这种“智能分工”逻辑是否正确</strong>。</p>
<hr />
<h3>🟢 Task 2：看懂辅助工具（Mock 类）</h3>
<p>代码开头定义的 <code>MockSaveStrategy</code> 和 <code>MockLoadStrategy</code> 是干嘛的？</p>
<ul>
<li><strong>痛点</strong>：单元测试不想真的要在硬盘上写几十 GB 的模型文件，太慢且占空间。</li>
<li><strong>Mock（模拟）</strong>：<ul>
<li><strong><code>MockSaveStrategy</code></strong>: 它假装自己是存储策略。当程序调用 <code>save</code> 时，它<strong>不写文件</strong>，而是拿个小本本记下来：“哦，Rank 0 试图保存 <code>keyA</code>，Rank 1 试图保存 <code>keyB</code>”。</li>
<li><strong><code>MockLoadStrategy</code></strong>: 假装加载。当程序要数据时，它直接生成一些假数据（比如全是 1 的张量）返回去，用来验证数据流通过程是否通畅。</li>
</ul>
</li>
</ul>
<p><strong>代码对应</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">MockSaveStrategy</span><span class="p">(</span><span class="n">SaveShardedStrategy</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">...</span><span class="p">):</span>
        <span class="c1"># ... 省略 ...</span>
        <span class="c1"># 只要记下来谁存了什么 key 就行，不真写磁盘</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_keys</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">sh_ten</span><span class="o">.</span><span class="n">key</span><span class="p">)</span>
</code></pre></div>

<hr />
<h3>🟢 Task 3：核心测试一 —— 谁来存？(<code>test_save_distribution</code>)</h3>
<p>这是文件里最重要的测试函数：<code>test_save_distribution</code>。</p>
<ul>
<li>
<p><strong>步骤 1：造数据</strong>
    <code>get_sharded_state_dict()</code> 构造了一个假的“模型状态字典”。里面有：</p>
<ul>
<li><code>keyB</code>: 每个人都有不同分片的数据（大家都要存）。</li>
<li><code>key_TP_repl1</code>: 张量并行的数据（部分人要存）。</li>
<li><code>keyD</code>: 一个巨大的张量（需要找个空闲的人存）。</li>
</ul>
</li>
<li>
<p><strong>步骤 2：预测分工（Expected）</strong>
    代码中写了一大堆 <code>expected_key_to_saving_ranks</code>。这是人类（开发者）手动算出来的“标准答案”。</p>
<ul>
<li><em>逻辑举例</em>：如果 <code>parallelization_along_dp=False</code>，<code>keyD</code> 是最大的张量，为了负载均衡，算法应该把它分配给 Rank 4 去存。</li>
</ul>
</li>
<li>
<p><strong>步骤 3：运行策略并对比</strong>
    <code>python
    save_strategy.save(state_dict, ckpt_dir_A) # 运行保存
    # ...
    # 对比 实际分配的Rank 和 预期的Rank 是否一致
    assert expected_key_to_saving_ranks == key_to_saving_rank</code></p>
</li>
</ul>
<p><strong>这个Task讲的是</strong>：验证算法是不是真的按照“最大张量优先、负载均衡”的原则分配了保存任务。</p>
<hr />
<h3>🟢 Task 4：核心测试二 —— 谁来读？(<code>test_load_distribution</code>)</h3>
<p>对应函数 <code>test_load_distribution</code>。</p>
<ul>
<li><strong>场景</strong>：保存完文件后，下次训练可能显卡数量变了，或者单纯读取。</li>
<li><strong>逻辑</strong>：<ul>
<li>加载比保存更复杂。因为可能 Rank 0 需要的数据，实际上是上次 Rank 4 存进硬盘的。</li>
<li>这个测试验证：当前 Rank 知道去哪里（哪个文件、哪个偏移量）找它需要的数据。</li>
</ul>
</li>
</ul>
<p><strong>代码对应</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 验证 mock 策略记录的加载 key 是否等于预期</span>
<span class="k">assert</span> <span class="n">mock_strategy</span><span class="o">.</span><span class="n">load_keys</span> <span class="o">==</span> <span class="n">expected_keys_loaded_by_current_rank</span>
</code></pre></div>

<hr />
<h3>🟢 Task 5：性能与优化测试 (<code>test_memory_usage</code> &amp; <code>test_only_necessary_exchanges</code>)</h3>
<p>开发者很担心两个性能问题，所以写了这两个测试：</p>
<ol>
<li>
<p><strong>内存爆炸 (<code>test_memory_usage</code>)</strong>：</p>
<ul>
<li><strong>问题</strong>：加载时，如果所有卡同时把数据读到内存里再分发，内存会爆。</li>
<li><strong>测试逻辑</strong>：记录 <code>torch.cuda.memory_allocated()</code>。加载过程中，内存峰值不能超过某个阈值（例如：不能超过单个张量大小的 4 倍）。如果超过了，说明代码写得烂，有内存泄漏或不必要的缓存。</li>
</ul>
</li>
<li>
<p><strong>不必要的通信 (<code>test_only_necessary_exchanges</code>)</strong>：</p>
<ul>
<li><strong>问题</strong>：如果 Rank 0 硬盘里有数据，Rank 0 自己读就行了。千万别搞成：Rank 0 读出来 -&gt; 广播给所有人 -&gt; 所有人发现只有 Rank 0 需要 -&gt; 浪费带宽。</li>
<li><strong>测试逻辑</strong>：
    <code>python
    # 统计 broadcast（广播）函数被调用的次数
    assert broadcast_mock.call_count == expected_count</code>
    如果我只需要加载 1 个张量，广播次数就不应该变成 2 次。</li>
</ul>
</li>
</ol>
<hr />
<h3>🟢 Task 6：高阶测试 —— 跨 Rank 读取 (<code>TestCrossRanksReads</code>)</h3>
<p>这是最难懂的部分，对应 <code>TestCrossRanksReads</code> 类。</p>
<ul>
<li><strong>场景</strong>：<ul>
<li><strong>保存时</strong>：Rank 0 存了张量 <code>A</code>，Rank 1 存了张量 <code>B</code>。</li>
<li><strong>加载时</strong>：Rank 1 想要张量 <code>A</code>，Rank 0 想要张量 <code>B</code>。</li>
</ul>
</li>
<li><strong>测试目标</strong>：验证这种“交叉读取”是否正确。</li>
<li><strong>关键逻辑</strong>：<ul>
<li><code>determine_cross_rank_reads</code> 函数模拟了一个保存和加载的过程。</li>
<li>它检查加载计划（Local Plan）：<ul>
<li><code>same_rank_reads</code>：我自己存的，我自己读（效率高）。</li>
<li><code>cross_rank_reads</code>：别人存的，我需要读（效率低，需要网络传输）。</li>
</ul>
</li>
<li>测试用例 <code>test_full_dp_reads</code> 等就是在不同的并行度设置下，检查这些读写关系是否符合预期。</li>
</ul>
</li>
</ul>
<hr />
<h3>💡 总结：这文件到底讲了啥？</h3>
<p>这个文件 <strong><code>test_fully_parallel.py</code></strong> 是一份质检报告。</p>
<p>它在说：</p>
<blockquote>
<p>“嘿，我写了一个叫 <code>FullyParallel</code> 的存取档策略。
为了证明它是对的，我模拟了各种复杂的显卡分布情况。
我保证：
1. 它能自动把大文件拆开给不同显卡存，不会累死某一个（负载均衡）。
2. 它知道怎么把拆散的数据拼回来（正确加载）。
3. 它不会偷偷吃掉太多显存（内存安全）。
4. 它不会乱发数据浪费网速（通信高效）。”</p>
</blockquote>
<p>如果你是使用者，你不需要看懂它；但如果你是 Megatron 的开发者，你需要通过它来确保你修改代码后，存取档功能不会挂掉。</p>