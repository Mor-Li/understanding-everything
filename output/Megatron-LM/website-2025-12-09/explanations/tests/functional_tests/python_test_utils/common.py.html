<h1>tests/functional_tests/python_test_utils/common.py</h1>
<p>这份代码其实是一个<strong>自动化测试工具</strong>的核心逻辑。它的主要作用是：<strong>拿你当前训练模型的“实测数据”，去和一份标准的“参考答案（Golden Values）”做对比，看看你的模型训练是否正常。</strong></p>
<p>通常在深度学习开发中，我们每次修改代码后，都要跑一下测试，确保新的改动没有破坏模型的精度或性能。</p>
<p>你可以把这个脚本想象成一个<strong>“阅卷老师”</strong>。为了让你理解，我把它拆解成一个 <strong>Task Todo List（任务清单）</strong>，一步步告诉你这位“阅卷老师”是怎么工作的。</p>
<hr />
<h3>阅卷老师的工作流程 (Task Todo List)</h3>
<h4>Task 1: 制定评分标准 (定义测试类型)</h4>
<p>首先，老师得心里有数，什么样的答案算对？
*   <strong>代码对应部分：</strong> <code>Test</code>, <code>ApproximateTest</code> (近似测试), <code>DeterministicTest</code> (确定性测试)。
*   <strong>解释：</strong>
    *   <strong>确定性测试 (<code>DeterministicTest</code>)</strong>：要求极其严格，必须一模一样（误差容忍度 <code>rtol</code>, <code>atol</code> 都是 0）。通常用于检查配置或固定逻辑。
    *   <strong>近似测试 (<code>ApproximateTest</code>)</strong>：比较宽容。因为GPU训练有随机性，只要数值在一定误差范围内（比如 <code>rtol=1e-5</code>），就算你过。</p>
<h4>Task 2: 准备标准答案 (定义数据结构)</h4>
<p>老师得把答案写在纸上，格式得统一。
*   <strong>代码对应部分：</strong> <code>GoldenValueMetric</code>, <code>GoldenValues</code>。
*   <strong>解释：</strong>
    *   这里定义了“答案”长什么样。比如：第10步 loss是多少，第20步 loss是多少。
    *   它记录了 <code>start_step</code> (开始步数), <code>end_step</code> (结束步数), <code>values</code> (具体数值)。</p>
<h4>Task 3: 收集考生的卷子 (读取 TensorBoard 日志)</h4>
<p>老师去收卷子了，也就是去读取你刚刚训练跑出来的日志文件。
*   <strong>代码对应部分：</strong> <code>read_tb_logs_as_list</code> 函数。
*   <strong>解释：</strong>
    1.  <strong>找文件</strong>：用 <code>glob</code> 在文件夹里搜 <code>events*tfevents*</code> (TensorBoard 的日志文件)。
    2.  <strong>读数据</strong>：加载这些文件，提取里面的 <code>scalars</code> (标量，比如 loss, accuracy, learning_rate)。
    3.  <strong>整理</strong>：按照指定的步长（比如每5步取一个数），把这些数据整理好，打包成上面定义的 <code>GoldenValueMetric</code> 格式。这就是“实测数据”。</p>
<h4>Task 4: 拿出标准答案 (读取 Golden Values JSON)</h4>
<p>老师从抽屉里拿出一份以前跑得最好的、确认没问题的数据作为对比标准。
*   <strong>代码对应部分：</strong> <code>read_golden_values_from_json</code> 函数。
*   <strong>解释：</strong>
    *   从一个 JSON 文件里读取数据，这些数据就是所谓的 "Golden Values"（金标准）。</p>
<h4>Task 5: 开始阅卷 (对比 Pipeline)</h4>
<p>这是最核心的一步，老师拿着“实测数据”和“标准答案”一行行比对。
*   <strong>代码对应部分：</strong> <code>pipeline</code> 函数。
*   <strong>解释：</strong>
    1.  <strong>一一对应</strong>：遍历每一个指标（比如 <code>loss</code>），看“考生”有没有做这道题。
    2.  <strong>特殊处理</strong>：如果是 <code>iteration-time</code> (每步耗时)，老师不看具体某一步，而是算一个<strong>中位数</strong>来比对（因为时间波动大，看中位数更准）。
    3.  <strong>数值比对</strong>：
        *   使用 <code>numpy</code> 的 <code>isclose</code> 方法。
        *   把“实测值”和“标准值”放进去，结合 Task 1 设定的容忍度（<code>rtol</code>, <code>atol</code>）。
        *   看看是不是足够接近。
    4.  <strong>判分逻辑</strong>：
        *   代码里有一个逻辑：<code>num_failing_steps_allowed</code>。意思是允许偶尔几步对不上（由总步数决定，最多允许50步出错）。
        *   如果大部分步骤都对上了（Passing rate 达标），就判定为 <strong>PASSED</strong>。
        *   如果误差太大，就报错（抛出异常），判定为 <strong>FAILED</strong>。</p>
<h3>总结</h3>
<p>这个文件的逻辑就是：</p>
<ol>
<li><strong>定义规则</strong>：什么是对，什么是错（误差范围）。</li>
<li><strong>读取实况</strong>：把你跑出来的 TensorBoard 日志读进内存。</li>
<li><strong>读取标准</strong>：把存好的 JSON 标准数据读进内存。</li>
<li><strong>执行比对</strong>：两组数据一碰，算出通过率，决定测试是成功还是失败。</li>
</ol>
<p><strong>一句话概括：</strong> 这是一个用来做<strong>回归测试（Regression Test）</strong>的脚本，确保你的模型训练指标（Loss、耗时等）和预期的一致，没有发生劣化。</p>