<h1>docs/source/api-guide/tokenizers.md</h1>
<p>这份文档其实是在介绍 <strong>Megatron-LM（一个大模型训练框架）引入的一套新的“分词器（Tokenizer）系统”</strong>。</p>
<p>简单来说，以前在 Megatron 里配置分词器很麻烦，现在他们改成了类似 Hugging Face 那种“傻瓜式”的用法。</p>
<p>为了帮你理解，我制定了一个 <strong>“从入门到精通”的 5 步任务清单 (Todo List)</strong>。你只需要跟着这个清单走，就能明白文档在说什么。</p>
<hr />
<h3>📋 任务清单：理解新版 Tokenizer 系统</h3>
<h4>✅ Task 1：搞懂“为什么要改？”（核心痛点）</h4>
<ul>
<li><strong>以前（旧系统）：</strong><ul>
<li>每次运行代码，你都要手动指定一大堆参数（比如：这是什么类型的 tokenizer？词表文件在哪？特殊的 token 是什么？）。</li>
<li>你必须自己在代码里写死（Hard-code）或者通过很长的命令行参数传进去。</li>
<li>你需要自己知道该用 <code>SentencePieceTokenizer</code> 类还是 <code>HuggingFaceTokenizer</code> 类，很累。</li>
</ul>
</li>
<li><strong>现在（新系统）：</strong><ul>
<li><strong>目标：</strong> 像 Hugging Face 一样简单。</li>
<li><strong>做法：</strong> 只需要告诉程序“文件夹在哪”，程序自动识别类型、自动加载配置。</li>
</ul>
</li>
</ul>
<h4>✅ Task 2：认识新系统的“身份证” —— Metadata（元数据）</h4>
<p>文档中反复提到的 <code>Metadata</code> (元数据) 是新系统的核心。
*   <strong>概念：</strong> 这是一个 <code>json</code> 文件（通常叫 <code>tokenizer_metadata.json</code>）。
*   <strong>作用：</strong> 它就像分词器的“身份证”。里面记录了：
    *   我是谁（比如我是 HuggingFace 还是 SentencePiece）。
    *   我的聊天模板（Chat Template）长啥样。
    *   我对应的 Python 类是哪个。
*   <strong>好处：</strong> 你只需要配置一次，生成这个 json 文件。以后把这个文件夹发给别人，别人直接加载就能用，不用再问你参数是多少。</p>
<h4>✅ Task 3：学习怎么“存”配置（Write Metadata）</h4>
<p>这是文档中 <code>Usage</code> 部分的第一段代码。
*   <strong>场景：</strong> 你刚准备好一个分词模型文件（比如 <code>tokenizer.model</code>），你想让它适应新系统。
*   <strong>操作：</strong> 使用 <code>.write_metadata()</code> 函数。
*   <strong>代码逻辑：</strong>
    <code>python
    # 告诉系统：我的模型文件在哪，我是什么类型的库(如 sentencepiece)
    MegatronTokenizer.write_metadata(
        tokenizer_path="/path/to/tokenizer.model",
        tokenizer_library="sentencepiece"
    )
    # 结果：系统会在目录下自动生成一个 .json 文件，把这些信息存下来。</code></p>
<h4>✅ Task 4：学习怎么“取”配置（Load Tokenizer）</h4>
<p>这是文档中 <code>Usage</code> 部分的第二段代码。
*   <strong>场景：</strong> 你要开始训练模型了，需要加载分词器。
*   <strong>操作：</strong> 使用 <code>.from_pretrained()</code> 函数（这名字和 Hugging Face 一模一样，为了让大家习惯）。
*   <strong>代码逻辑：</strong>
    <code>python
    # 只要给路径，系统自动去读那个 json 身份证，然后自动把分词器加载好
    tokenizer = MegatronTokenizer.from_pretrained(
        tokenizer_path="/path/to/tokenizer.model"
    )</code>
*   <strong>重点：</strong> 你不需要再关心底层是用什么类实现的，系统自动搞定。</p>
<h4>✅ Task 5：实战 —— 在训练脚本里怎么用？</h4>
<p>文档最后一部分 <code>Megatron-LM pretraining compatibility</code> 讲的是实际跑训练命令时的变化。
*   <strong>新用法：</strong>
    如果你用 <code>torchrun</code> 跑预训练，只需要加一个参数 <code>--tokenizer-metadata</code> 指向那个 json 文件即可。
    *   <em>注：如果不指定，它甚至会尝试自动生成一个默认的。</em>
*   <strong>旧用法兼容（后悔药）：</strong>
    如果你不想用新系统，想用以前的老方法，加上 <code>--legacy-tokenizer</code> 这个参数，系统就会切回老模式。</p>
<hr />
<h3>总结一下</h3>
<p>这篇文档就在讲一件事：</p>
<p><strong>Megatron-LM 把分词器的加载方式升级了。</strong>
1.  <strong>以前：</strong> 手动挡汽车，上坡要自己配合离合油门（手动传参，容易出错）。
2.  <strong>现在：</strong> 自动挡汽车，挂上 D 档（<code>.from_pretrained</code>）就能走，所有配置信息都存在行车电脑（<code>metadata.json</code>）里。</p>