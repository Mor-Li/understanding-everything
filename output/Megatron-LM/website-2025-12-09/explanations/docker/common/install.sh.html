<h1>docker/common/install.sh</h1>
<p>这份脚本确实看起来有点复杂，因为它包含了参数解析、系统级安装、硬件驱动配置以及两种不同的 Python 包管理逻辑。</p>
<p>简单来说，这是一个 <strong>自动化安装脚本</strong>，通常在构建 Docker 镜像的过程中运行。它的核心目的是：<strong>在一个裸的 Linux 系统上，把运行这个项目所需的一切（Python、CUDA、依赖包）都装好。</strong></p>
<p>为了让你容易理解，我把它拆解成一个 <strong>“装修房子”的任务清单 (Task List)</strong>。你可以想象这个脚本就是一个装修队工头，正在按顺序执行以下任务：</p>
<hr />
<h3>📝 任务清单：环境搭建五步走</h3>
<h4>Task 1: 接单与核对需求 (参数解析)</h4>
<p><strong>代码位置：</strong> 开头到 <code>main()</code> 之前
<strong>他在做什么：</strong>
工头（脚本）先问你（用户）：
*   <code>--base-image</code>: 房子原本是毛坯（Ubuntu）还是简装（PyTorch 官方镜像）？
*   <code>--python-version</code>: 想要哪个版本的 Python（默认 3.12）？
*   <code>--environment</code>: 是开发环境（dev）还是长期支持环境（lts）？
*   <code>--use-uv</code>: 是否使用 <code>uv</code> 这个新型快速工具来安装家具（依赖包）？</p>
<p><strong>这一步的产出：</strong> 确定了具体的安装方案，如果参数不对（比如没填基础镜像），直接报错罢工。</p>
<h4>Task 2: 搞定“通行证” (权限配置)</h4>
<p><strong>代码位置：</strong> <code>main</code> 函数开头 (<code>if [[ -n "${PAT:-}" ]]; then ...</code>)
<strong>他在做什么：</strong>
如果你提供了 <code>PAT</code> (GitHub 的访问令牌)，脚本会把它写进系统的 <code>~/.netrc</code> 文件里。
<strong>为什么：</strong> 这样后续下载私有代码库时，就不用手动输密码了，机器能自动通过验证。</p>
<h4>Task 3: 基础设施建设 (安装 Python 和工具)</h4>
<p><strong>代码位置：</strong> <code># Install Python</code> 和 <code># Install tools</code> 部分
<strong>他在做什么：</strong>
1.  <strong>装 Python：</strong> 通过 <code>apt-get</code> 从 PPA 源安装指定版本的 Python (如 3.12) 和开发头文件 (<code>-dev</code>)。
2.  <strong>设置默认：</strong> 把 <code>python3</code> 命令指向刚装好的这个版本。
3.  <strong>装工具：</strong> 安装 <code>wget</code>, <code>curl</code>, <code>git</code>, <code>cmake</code> 等常用工具，相当于买梯子、锤子、螺丝刀。</p>
<h4>Task 4: 显卡驱动与加速库 (安装 CUDA)</h4>
<p><strong>代码位置：</strong> <code># Install CUDA</code> 部分
<strong>他在做什么：</strong>
这里有个判断逻辑：
*   <strong>如果是 Ubuntu 基础镜像：</strong> 这相当于毛坯房，啥都没有。脚本会去 NVIDIA 官网下载并安装 CUDA Toolkit 12.8 和 cuDNN。这是为了让显卡能跑 AI 计算。
*   <strong>如果是 PyTorch 基础镜像：</strong> 相当于简装房，原厂已经装好了 CUDA，所以这一步直接跳过，避免重复安装冲突。</p>
<h4>Task 5: 进场安装家具 (安装 Python 依赖包)</h4>
<p><strong>代码位置：</strong> 脚本的后半部分 (从 <code>unset PIP_CONSTRAINT</code> 开始)
<strong>他在做什么：</strong>
这是最核心的一步，安装项目所需的 Python 库。这里分了两条路（根据 Task 1 里的 <code>--use-uv</code> 决定）：</p>
<ul>
<li>
<p><strong>路线 A：使用 <code>uv</code> (新潮、快速的方式)</strong></p>
<ol>
<li><strong>排除重复：</strong> 如果基础镜像是 PyTorch，脚本会列出一堆清单 (<code>UV_ARGS</code>)，告诉 <code>uv</code>：“Torch 和 NVIDIA 的那些库墙上已经有了，<strong>千万别再装一遍</strong>”。</li>
<li><strong>装工具：</strong> 下载安装 <code>uv</code> (一个超快的包管理器)。</li>
<li><strong>建环境：</strong> 创建虚拟环境 (<code>venv</code>)。</li>
<li><strong>同步依赖：</strong> 运行 <code>uv sync</code>，根据 <code>pyproject.toml</code> 或锁文件把所有依赖装好。</li>
<li><strong>安装本项目：</strong> 最后把当前代码库安装进去。</li>
</ol>
</li>
<li>
<p><strong>路线 B：使用 <code>pip</code> (传统、老派的方式)</strong></p>
<ol>
<li><strong>建环境：</strong> 用标准的 <code>python3 -m venv</code> 创建虚拟环境并激活。</li>
<li><strong>装基础：</strong> 更新 <code>pip</code>，安装构建工具 (<code>ninja</code>, <code>wheel</code>, <code>packaging</code>)。</li>
<li><strong>装 Torch：</strong> 这一步会直接安装 Torch 相关的包。</li>
<li><strong>安装本项目：</strong> 运行 <code>pip install .</code> 把当前项目装好。</li>
</ol>
</li>
</ul>
<hr />
<h3>总结</h3>
<p>这个脚本就是在做一件事：<strong>从零开始配置一台能跑这个 AI 项目的 Linux 机器。</strong></p>
<ul>
<li>它很智能：知道如果你用了 PyTorch 镜像，就不重复装 CUDA。</li>
<li>它很灵活：你可以选是用传统的 <code>pip</code> 慢吞吞装，还是用新的 <code>uv</code> 飞快地装。</li>
</ul>