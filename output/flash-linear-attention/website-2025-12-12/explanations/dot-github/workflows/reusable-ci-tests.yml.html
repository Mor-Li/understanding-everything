<h1>.github/workflows/reusable-ci-tests.yml</h1>
<p>这份文件名为 <code>reusable-ci-tests.yml</code>，它的核心作用是一个<strong>“可重用的自动化测试流程模板”</strong>。</p>
<p>简单来说，它不是直接运行的，而是被其他配置文件调用的。它的任务是：<strong>在一个指定的服务器（Runner）上，配置好 Python/Conda 环境，安装指定版本的 PyTorch 和 CUDA，然后运行代码测试。</strong></p>
<p>我把它想象成一个<strong>“测试机器人”</strong>，下面是这个机器人接到任务后，手里拿的那张 <strong>Todo List（任务清单）</strong>。</p>
<hr />
<h3>📋 任务清单：自动化测试流程 (Todo List)</h3>
<h4>第一阶段：接单 (Inputs)</h4>
<p>机器人首先会确认这次任务的具体要求（即 <code>inputs</code> 部分）：
- [ ] <strong>确认在哪台机器跑</strong> (<code>runner</code>): 比如是 H100 显卡机器。
- [ ] <strong>确认显卡类型</strong> (<code>gpu_type</code>): 是 NVIDIA 还是 Intel。
- [ ] <strong>确认基础环境名</strong> (<code>conda_env_name</code>): 比如叫 <code>fla-test</code>。
- [ ] <strong>确认软件版本</strong> (<code>pytorch_version</code>, <code>cuda</code>): 比如 PyTorch 2.7.0, CUDA 12.8。</p>
<hr />
<h4>第二阶段：任务 A - 测试基础算子 (<code>test-ops</code> Job)</h4>
<p>这是第一波测试，主要测试代码库里最底层的数学运算（Ops）是否正常。</p>
<p><strong>1. 准备工作 (Setup)</strong>
- [ ] <strong>下载代码</strong>: 把 GitHub 仓库里的最新代码拉取下来。
- [ ] <strong>检查是否跳过</strong>: 看一下最新提交的 commit 信息里有没有写 <code>[skip test]</code>。如果写了，直接下班（跳过测试）。
- [ ] <strong>🔍 寻找/锁定 Conda 环境 (重点逻辑)</strong>:
    - <em>逻辑</em>: 机器人会看自己是在哪台机器上（比如 <code>nvidia-h100-1</code> 还是 <code>nvidia-h100-2</code>）。
    - <em>目的</em>: 为了防止冲突，不同的机器可能需要激活带后缀的环境名（比如 <code>env_name_1</code>）。
    - <em>动作</em>: 找到 Conda 的安装路径，并设置好环境变量。
- [ ] <strong>安装/更新依赖包</strong>:
    - 卸载旧版本的 <code>flash-linear-attention</code>。
    - 根据输入的 PyTorch 版本（是正式版还是 Nightly 版）下载对应的包。
    - 如果是 NVIDIA H100 显卡，额外安装 <code>causal-conv1d</code>, <code>flash-attn</code>, <code>mamba_ssm</code> 等高性能库。
    - <strong>最后安装当前代码库</strong> (<code>pip install .</code>)。</p>
<p><strong>2. 验证环境</strong>
- [ ] <strong>检查 GPU</strong>: 运行一个 Python 脚本 <code>check_gpu.py</code>，确认显卡是否可用、是否被占用。如果被占用，报错并停止。</p>
<p><strong>3. 执行测试</strong>
- [ ] <strong>分析变动</strong>: 看看这次代码提交修改了哪些文件。
- [ ] <strong>筛选测试用例</strong>: 运行脚本 <code>find_dependent_tests.py</code>，根据修改的文件，智能找出需要运行的 <strong>Ops（算子）</strong> 测试文件。
- [ ] <strong>运行测试</strong>: 使用 <code>pytest</code> 运行筛选出来的测试文件。</p>
<hr />
<h4>第三阶段：任务 B - 测试模型 (<code>test-models</code> Job)</h4>
<p>只有当“任务 A”成功完成后，才会开始这个任务。这部分测试完整的模型结构。</p>
<p><strong>1. 准备工作 (Setup - 重复流程)</strong>
<em>注意：虽然是同一台机器，但 GitHub Actions 的 Job 之间通常是隔离的，所以需要重新走一遍流程，或者确保环境状态一致。</em>
- [ ] <strong>等待</strong>: 确保 <code>test-ops</code> 任务成功（<code>needs: test-ops</code>）。
- [ ] <strong>下载代码</strong>: 再次拉取代码。
- [ ] <strong>检查是否跳过</strong>: 同上。
- [ ] <strong>锁定 Conda 环境</strong>: 使用和任务 A 相同的逻辑锁定环境（这里针对 H100-3 还有特殊的逻辑，如果是 nightly 版本怎么处理等）。
- [ ] <strong>安装依赖</strong>: 再次确认依赖安装正确（卸载旧的，安装新的 PyTorch 和相关库）。</p>
<p><strong>2. 执行测试</strong>
- [ ] <strong>分析变动</strong>: 再次查看修改了哪些文件。
- [ ] <strong>筛选测试用例</strong>: 运行脚本 <code>find_dependent_tests.py</code>，这次参数变了，专门筛选 <strong>Models（模型）</strong> 相关的测试文件。
- [ ] <strong>运行测试</strong>: 使用 <code>pytest</code> 运行模型测试。</p>
<hr />
<h3>💡 核心观点与逻辑解读 (Key Takeaways)</h3>
<p>如果你看不懂代码，只需要理解作者在里面设计的几个<strong>核心“心机”</strong>：</p>
<ol>
<li>
<p><strong>环境隔离与并发控制 (The H100 Logic)</strong>:</p>
<ul>
<li>在 <code>Discover Conda Path</code> 这一步，你会看到大量的 <code>if runner.name == ...</code>。</li>
<li><strong>观点</strong>: 作者有很多台自托管（Self-hosted）的 H100 服务器。为了防止多个测试任务同时跑在一台机器上把环境搞乱，脚本会根据机器名字（比如 <code>h100-1</code>, <code>h100-2</code>）自动切换 Conda 环境名（<code>env</code> vs <code>env_1</code>）。这是一种简易的<strong>资源隔离策略</strong>。</li>
</ul>
</li>
<li>
<p><strong>智能测试 (Smart Testing)</strong>:</p>
<ul>
<li>脚本没有无脑运行所有测试（<code>pytest .</code>），而是先运行 <code>changed-files</code> 插件，再跑 <code>find_dependent_tests.py</code>。</li>
<li><strong>观点</strong>: 这是一个<strong>省时策略</strong>。只测试被修改代码影响到的部分，而不是每次都跑全量测试，能显著缩短 CI 时间。</li>
</ul>
</li>
<li>
<p><strong>分层测试 (Ops vs Models)</strong>:</p>
<ul>
<li>把测试分成了 <code>test-ops</code>（算子）和 <code>test-models</code>（模型）两个 Job。</li>
<li><strong>观点</strong>: <strong>快速失败（Fail Fast）原则</strong>。算子是基础，如果算子都挂了，跑模型测试毫无意义且浪费资源。所以 <code>test-models</code> 必须等 <code>test-ops</code> 绿了之后才跑。</li>
</ul>
</li>
<li>
<p><strong>兼容性矩阵</strong>:</p>
<ul>
<li>脚本里大量判断 <code>inputs.pytorch_version</code> 是 "nightly" 还是稳定版，是 "nvidia" 还是 "intel"。</li>
<li><strong>观点</strong>: 这个库非常依赖硬件底层（CUDA/Triton），所以必须严格控制依赖包的版本来源（index-url），否则很容易出现环境不兼容。</li>
</ul>
</li>
</ol>