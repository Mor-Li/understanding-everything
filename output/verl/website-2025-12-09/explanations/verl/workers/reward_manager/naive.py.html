<h1>verl/workers/reward_manager/naive.py</h1>
<p>这份代码 <code>naive.py</code> 实现了一个叫做 <code>NaiveRewardManager</code> 的类。</p>
<p>在强化学习（RL）训练大模型（LLM）的过程中，模型生成了回答，我们需要给这个回答打分（Reward），告诉模型好不好。这个类的作用就是<strong>“阅卷老师”</strong>。</p>
<p>它之所以叫 "Naive"（朴素），是因为它通常不使用复杂的神经网络来打分，而是通过<strong>规则</strong>（比如做数学题，答案对不对）或者<strong>简单的比对</strong>来计算分数。</p>
<p>为了让你看懂，我把你（作为这个阅卷老师）需要做的事情列成了一个 <strong>ToDo List</strong>，然后一步步解释代码是怎么执行这个清单的。</p>
<hr />
<h3>阅卷老师的 ToDo List (任务清单)</h3>
<ol>
<li><strong>准备阶段 (<code>__init__</code>)</strong>：带上翻译机（Tokenizer），确定打分规则（compute_score），设定抽查数量。</li>
<li><strong>预检阶段 (<code>__call__</code> 开头)</strong>：检查一下这些卷子是不是已经有分数了？如果有，直接上报，不干活了。</li>
<li><strong>准备成绩单</strong>：拿一张和卷子一样大的空白表格（Tensor），准备填分。</li>
<li><strong>逐个阅卷 (循环 Loop)</strong>：<ul>
<li><strong>步骤 A (整理卷面)</strong>：把学生写的答案里的“空白占位符”（Padding）去掉，只看有效内容。</li>
<li><strong>步骤 B (翻译)</strong>：学生写的是数字代码（Token IDs），用翻译机转成人类能懂的文字（String）。</li>
<li><strong>步骤 C (对答案)</strong>：拿出标准答案（Ground Truth），对比学生的回答，计算得分。</li>
<li><strong>步骤 D (填分)</strong>：把分数写在成绩单上（通常写在回答结束的最后一个字那里）。</li>
<li><strong>步骤 E (抽查)</strong>：如果是前几份卷子，大声念出来给大家听听（Print），方便检查逻辑对不对。</li>
</ul>
</li>
<li><strong>交卷</strong>：把填好分数的成绩单交上去。</li>
</ol>
<hr />
<h3>详细代码对应讲解</h3>
<h4>1. 准备阶段 (<code>__init__</code>)</h4>
<p>这是类的初始化函数。</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">num_examine</span><span class="p">,</span> <span class="n">compute_score</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reward_fn_key</span><span class="o">=</span><span class="s2">&quot;data_source&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="c1"># ...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>  <span class="c1"># 翻译机：把数字转成文字</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_examine</span> <span class="o">=</span> <span class="n">num_examine</span>  <span class="c1"># 抽查数量：比如只想看前5个样本的打印结果</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">compute_score</span> <span class="o">=</span> <span class="n">compute_score</span> <span class="ow">or</span> <span class="n">default_compute_score</span> <span class="c1"># 打分规则：如果不传，就用默认的</span>
</code></pre></div>

<ul>
<li><strong>观点</strong>：这里只是存一下工具。最关键的是 <code>compute_score</code>，它是一个函数，输入你的答案和标准答案，输出一个分数（比如 1.0 或 0.0）。</li>
</ul>
<h4>2. 预检阶段 (<code>__call__</code> 的开头)</h4>
<p>当你被调用时（<code>__call__</code>），你收到了一批数据 <code>data</code>。</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 如果数据里已经包含了 &quot;rm_scores&quot; (Reward Model Scores)，说明上游已经算好了</span>
<span class="k">if</span> <span class="s2">&quot;rm_scores&quot;</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="c1"># 直接返回现成的分数，不做重复劳动</span>
    <span class="k">if</span> <span class="n">return_dict</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">...</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;rm_scores&quot;</span><span class="p">]</span>
</code></pre></div>

<ul>
<li><strong>观点</strong>：效率优先，不重复造轮子。</li>
</ul>
<h4>3. 准备成绩单</h4>
<p>如果没有现成的分数，就要开始干活了。</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 创建一个全是 0 的张量 (Tensor)，形状和 responses 一样</span>
<span class="c1"># 比如 batch_size=2, sequence_length=100</span>
<span class="n">reward_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;responses&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</code></pre></div>

<ul>
<li><strong>观点</strong>：初始化一个全零的矩阵，稍后我们只在特定的位置（回答结束的地方）填入非零的分数。</li>
</ul>
<h4>4. 逐个阅卷 (核心循环)</h4>
<p>这是代码最长的地方，遍历 Batch 里的每一个样本。</p>
<div class="codehilite"><pre><span></span><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)):</span>
    <span class="n">data_item</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="c1"># 拿出一份卷子</span>
</code></pre></div>

<p><strong>步骤 A: 整理卷面 (处理 Mask)</strong>
模型输入通常是固定长度的，不够长的地方会补 0 (Padding)。我们需要去掉这些 0。</p>
<div class="codehilite"><pre><span></span><code><span class="n">prompt_ids</span> <span class="o">=</span> <span class="n">data_item</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;prompts&quot;</span><span class="p">]</span>
<span class="c1"># ... 计算有效的 prompt 长度 ...</span>
<span class="n">valid_prompt_ids</span> <span class="o">=</span> <span class="n">prompt_ids</span><span class="p">[</span><span class="o">-</span><span class="n">valid_prompt_length</span><span class="p">:]</span> <span class="c1"># 截取有效的问题部分</span>

<span class="n">response_ids</span> <span class="o">=</span> <span class="n">data_item</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;responses&quot;</span><span class="p">]</span>
<span class="c1"># ... 计算有效的 response 长度 ...</span>
<span class="n">valid_response_ids</span> <span class="o">=</span> <span class="n">response_ids</span><span class="p">[:</span><span class="n">valid_response_length</span><span class="p">]</span> <span class="c1"># 截取有效的回答部分</span>
</code></pre></div>

<p><strong>步骤 B: 翻译 (Decode)</strong>
打分函数通常看不懂 <code>[101, 2045, ...]</code> 这种数字，它需要看 "The answer is 42"。</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 把数字 ID 变成字符串</span>
<span class="n">prompt_str</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">valid_prompt_ids</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">response_str</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">valid_response_ids</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<p><strong>步骤 C: 对答案 (Compute Score)</strong>
这一步是灵魂。</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 从数据里拿出标准答案</span>
<span class="n">ground_truth</span> <span class="o">=</span> <span class="n">data_item</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;reward_model&quot;</span><span class="p">][</span><span class="s2">&quot;ground_truth&quot;</span><span class="p">]</span>
<span class="c1"># ... 获取其他辅助信息 ...</span>

<span class="c1"># 调用打分函数！</span>
<span class="n">score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_score</span><span class="p">(</span>
    <span class="n">data_source</span><span class="o">=</span><span class="n">data_source</span><span class="p">,</span>
    <span class="n">solution_str</span><span class="o">=</span><span class="n">response_str</span><span class="p">,</span> <span class="c1"># 学生的回答</span>
    <span class="n">ground_truth</span><span class="o">=</span><span class="n">ground_truth</span><span class="p">,</span> <span class="c1"># 标准答案</span>
    <span class="n">extra_info</span><span class="o">=</span><span class="n">extra_info</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div>

<ul>
<li><strong>观点</strong>：这里的逻辑被封装在 <code>compute_score</code> 里了。可能是检查数学题答案是否匹配，也可能是检查代码是否通过测试用例。</li>
</ul>
<p><strong>步骤 D: 填分 (Assign)</strong>
这是一个强化学习（PPO等算法）特有的细节：<strong>分数通常给在回答结束的最后一个 Token 上</strong>。</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 如果 response 有 10 个词，我们在第 10 个词的位置填入分数</span>
<span class="c1"># 其他位置保持为 0</span>
<span class="n">reward_tensor</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">valid_response_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward</span>
</code></pre></div>

<ul>
<li><strong>解释</strong>：为什么不每个词都给分？因为我们是对“整个回答”打分，只有读完最后一个字，才知道这个回答好不好。</li>
</ul>
<p><strong>步骤 E: 抽查展示 (Print)</strong>
为了方便调试，打印前几个样本看看。</p>
<div class="codehilite"><pre><span></span><code><span class="k">if</span> <span class="n">already_print_data_sources</span><span class="p">[</span><span class="n">data_source</span><span class="p">]</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_examine</span><span class="p">:</span>
    <span class="c1"># 打印问题、回答、标准答案、分数</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[prompt]&quot;</span><span class="p">,</span> <span class="n">prompt_str</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[response]&quot;</span><span class="p">,</span> <span class="n">response_str</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[score]&quot;</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span>
    <span class="c1"># ...</span>
</code></pre></div>

<h4>5. 交卷 (Return)</h4>
<p>循环结束后，返回填好分数的 Tensor。</p>
<div class="codehilite"><pre><span></span><code><span class="k">if</span> <span class="n">return_dict</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;reward_tensor&quot;</span><span class="p">:</span> <span class="n">reward_tensor</span><span class="p">,</span>
        <span class="s2">&quot;reward_extra_info&quot;</span><span class="p">:</span> <span class="n">reward_extra_info</span><span class="p">,</span>
    <span class="p">}</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">reward_tensor</span>
</code></pre></div>

<hr />
<h3>总结</h3>
<p>这个文件的核心逻辑就是：
<strong>把模型生成的“数字ID”转回“文本”，拿去和“标准答案”做对比算出分数，然后把分数填回到对应的数据结构中，供强化学习算法更新模型使用。</strong></p>