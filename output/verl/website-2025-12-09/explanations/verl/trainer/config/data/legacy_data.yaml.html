<h1>verl/trainer/config/data/legacy_data.yaml</h1>
<p>别担心，看到这种密密麻麻的配置文件（Config File）感到头大是很正常的。</p>
<p>简单来说，这个文件就是<strong>给AI训练程序的一份“购物清单”和“烹饪指南”</strong>。它告诉程序：去哪里买菜（数据在哪）、切多大块（文本长度）、一次煮多少（Batch Size）、以及怎么处理特殊的食材（多模态/图片）。</p>
<p>为了让你好理解，我把你作为<strong>“训练大厨”</strong>需要做的决定，拆解成了一个 <strong>Todo List（待办清单）</strong>。</p>
<p>请按照这个顺序来看这个文件中的各个参数：</p>
<hr />
<h3>📋 任务清单：配置你的训练数据</h3>
<h4>✅ 第一步：告诉程序“食材”（数据）在哪里？</h4>
<p>首先，程序得知道去哪里读取训练数据。
*   <strong><code>train_files</code></strong>: 训练集在哪里？（例如：<code>~/data/rlhf/gsm8k/train.parquet</code>）。
*   <strong><code>val_files</code></strong>: 考试题（验证集）在哪里？用来测试模型学得怎么样的。
*   <strong><code>tokenizer</code></strong>: 用哪本字典来读数据？如果填 <code>null</code>，程序会自动根据模型去猜。</p>
<h4>✅ 第二步：规定“切菜”的尺寸（文本长度）</h4>
<p>模型吃不下无限长的数据，你需要设定界限。
*   <strong><code>max_prompt_length</code></strong>: 提问（Prompt）最长能有多长？（这里设了 512）。如果太长了怎么办？看下面的 <code>truncation</code>。
*   <strong><code>max_response_length</code></strong>: 模型回答（Response）最长能写多少字？（这里设了 512）。
*   <strong><code>truncation</code></strong>: 如果提问超过了长度，怎么切？默认是 <code>'error'</code>（直接报错），也可以选 <code>'right'</code>（切掉后面的）等。
*   <strong><code>filter_overlong_prompts</code></strong>: 或者干脆把太长的提问直接扔掉，不练了？（这里设了 <code>False</code>，不扔）。</p>
<h4>✅ 第三步：指认数据的“部位”（数据列名）</h4>
<p>你的数据文件（parquet）里可能有很多列，程序不知道哪一列是提问，哪一列是图片。
*   <strong><code>prompt_key</code></strong>: 哪一列是提示词？（默认叫 <code>'prompt'</code>）。
*   <strong><code>image_key</code></strong> / <strong><code>video_key</code></strong>: 如果有图或视频，它们在哪一列？
*   <strong><code>reward_fn_key</code></strong>: 如果你需要根据数据来源给不同的奖励（Reward），看哪一列？</p>
<h4>✅ 第三步半：决定一次“煮”多少（Batch Size）</h4>
<ul>
<li><strong><code>train_batch_size</code></strong>: 训练时，一次往模型里塞多少条数据？（这里是 1024，很大）。</li>
<li><strong><code>val_batch_size</code></strong>: 验证时，一次塞多少？</li>
</ul>
<h4>✅ 第四步：数据预处理（洗菜和摆盘）</h4>
<p>在喂给模型前，数据要不要做特殊处理？
*   <strong><code>shuffle</code></strong>: 要不要把数据打乱顺序？（通常训练都要打乱，设为 <code>True</code>）。
*   <strong><code>return_raw_chat</code></strong>: 是否保留原始的对话格式，不加特殊的聊天模板？
*   <strong><code>dataloader_num_workers</code></strong>: 雇几个“帮厨”（CPU线程）来加载数据？（这里是 8 个，为了读数据快一点）。</p>
<h4>✅ 第五步：高级设置（给高阶大厨用的）</h4>
<p>如果你的数据很特殊（比如有图片，或者需要自定义代码），才看这里。
*   <strong><code>use_shm</code></strong>: 是否使用共享内存？（加速用的，默认关）。
*   <strong><code>custom_cls</code></strong>: 你是不是自己写了特殊的 Python 代码来加载数据？如果是，在这里填路径。
*   <strong><code>datagen</code></strong>: 是否需要程序自动生成一些数据来扩充？</p>
<hr />
<h3>💡 总结一下文中的核心观点</h3>
<p>这个文件其实就在表达一件事：<strong>“如何把原始的数据文件，标准化成模型能吃进去的格式。”</strong></p>
<p>如果我们要把这个文件翻译成人话，它在说：</p>
<blockquote>
<p>“嘿，程序！去 <code>~/data/...</code> 目录下把 parquet 文件读进来。
别管那些太长的数据，把提问限制在 512 长度以内。
每次给我拿 1024 条数据出来，记得把顺序打乱。
还有，这一列是‘提问’，那一列是‘图片’，别搞错了！”</p>
</blockquote>
<p><strong>你现在只需要关注这三个最关键的：</strong>
1.  <strong>路径对不对？</strong> (<code>train_files</code>)
2.  <strong>长度够不够？</strong> (<code>max_prompt_length</code>) —— 设太短模型学不到东西，设太长显存会爆。
3.  <strong>Batch大不大？</strong> (<code>train_batch_size</code>) —— 决定了训练速度和显存占用。</p>
<p>现在看是不是清晰一点了？</p>