<h1>recipe/dapo/run_dapo_qwen3_moe_30b_megatron_npu.sh</h1>
<p>这份代码看起来确实很吓人，因为它充满了技术术语和复杂的参数。但别担心，我们把它想象成<strong>“给超级计算机下达的一张详细的做菜清单”</strong>。</p>
<p>这份脚本（<code>.sh</code> 文件）的唯一目的就是：<strong>启动一个大规模的 AI 模型训练任务</strong>。</p>
<p>为了让你看懂，我列了一个 <strong>Task To-Do List（任务清单）</strong>，带你一步步拆解这份“做菜指南”：</p>
<hr />
<h3>✅ Task 1: 搞清楚我们要“做什么菜” (宏观目标)</h3>
<p><strong>代码对应部分：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="nv">project_name</span><span class="o">=</span><span class="s1">&#39;DAPO&#39;</span>
<span class="nv">exp_name</span><span class="o">=</span><span class="s1">&#39;DAPO-Qwen3-30B-megatron&#39;</span>
</code></pre></div>

<ul>
<li><strong>解读：</strong><ul>
<li><strong>项目名</strong>：DAPO（这是一种特定的训练算法）。</li>
<li><strong>实验名</strong>：用 DAPO 方法训练 <strong>Qwen3-30B</strong>（通义千问3代，300亿参数版本）模型。</li>
<li><strong>核心目标</strong>：这是一个<strong>强化学习（RL）</strong>的训练任务，目的是让模型在数学题上表现更好（后面提到了 math 数据集）。</li>
</ul>
</li>
</ul>
<hr />
<h3>✅ Task 2: 准备“食材”和“厨具” (基础配置)</h3>
<p><strong>代码对应部分：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="nv">TRAIN_FILE</span><span class="o">=</span>.../dapo-math-17k.parquet
<span class="nv">TEST_FILE</span><span class="o">=</span>.../aime-2024.parquet
<span class="nv">MODEL_PATH</span><span class="o">=</span>.../Qwen3-30B-A3B
...
trainer.device<span class="o">=</span><span class="s2">&quot;npu&quot;</span>
</code></pre></div>

<ul>
<li><strong>解读：</strong><ul>
<li><strong>食材（数据）</strong>：训练数据是 <code>dapo-math-17k</code>（数学题），测试数据是 <code>aime-2024</code>（竞赛题）。</li>
<li><strong>原料（模型）</strong>：基础模型加载自 <code>Qwen3-30B-A3B</code>。</li>
<li><strong>厨具（硬件）</strong>：注意文件名和配置里的 <code>npu</code>。这说明不是用常见的 NVIDIA GPU，而是用<strong>华为昇腾 NPU</strong> 进行训练。</li>
</ul>
</li>
</ul>
<hr />
<h3>✅ Task 3: 设定“烹饪火候” (算法超参)</h3>
<p><strong>代码对应部分：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="nv">adv_estimator</span><span class="o">=</span>grpo
<span class="nv">kl_coef</span><span class="o">=</span><span class="m">0</span>.0
<span class="nv">max_prompt_length</span><span class="o">=</span><span class="k">$((</span><span class="m">1024</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="m">2</span><span class="k">))</span>
<span class="nv">max_response_length</span><span class="o">=</span><span class="k">$((</span><span class="m">1024</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="m">20</span><span class="k">))</span>
</code></pre></div>

<ul>
<li><strong>解读：</strong><ul>
<li><strong>算法</strong>：<code>grpo</code>。这是一种最近很火的强化学习算法（类似 DeepSeek-R1 背后的技术），不用传统的 Critic 模型，更省显存。</li>
<li><strong>长度限制</strong>：<ul>
<li>题目最长：2048 token。</li>
<li>回答最长：20480 token（允许模型进行很长的思考链 CoT）。</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr />
<h3>✅ Task 4: 安排“厨师分工” (分布式并行策略)</h3>
<p>这是最复杂的部分，因为模型太大（30B），一张卡装不下，需要切分。
<strong>代码对应部分：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Megatron backend</span>
<span class="nv">train_tp</span><span class="o">=</span><span class="m">4</span><span class="w">  </span><span class="c1"># Tensor Parallel (张量并行)</span>
<span class="nv">train_ep</span><span class="o">=</span><span class="m">2</span><span class="w">  </span><span class="c1"># Expert Parallel (专家并行，因为是 MoE 模型)</span>
<span class="nv">train_pp</span><span class="o">=</span><span class="m">2</span><span class="w">  </span><span class="c1"># Pipeline Parallel (流水线并行)</span>
</code></pre></div>

<ul>
<li><strong>解读：</strong><ul>
<li>这是一个 <strong>Megatron</strong> 架构的训练。</li>
<li><strong>切分策略</strong>：模型被切得非常细。<ul>
<li><code>tp=4</code>：一个层切成4份。</li>
<li><code>pp=2</code>：模型的前一半层和后一半层放在不同卡上。</li>
<li><code>ep=2</code>：MoE 模型的专家层也被切分了。</li>
</ul>
</li>
<li><strong>意思就是</strong>：这需要很多张显卡（NPU）协同工作，每张卡只负责模型的一小部分。</li>
</ul>
</li>
</ul>
<hr />
<h3>✅ Task 5: 启动“流水线” (执行命令)</h3>
<p><strong>代码对应部分：</strong></p>
<div class="codehilite"><pre><span></span><code>ray<span class="w"> </span>job<span class="w"> </span>submit<span class="w"> </span>...<span class="w"> </span>--<span class="w"> </span>python3<span class="w"> </span>-m<span class="w"> </span>recipe.dapo.main_dapo<span class="w"> </span>...
</code></pre></div>

<ul>
<li><strong>解读：</strong><ul>
<li>这是整个脚本的<strong>“发射按钮”</strong>。</li>
<li><code>ray job submit</code>：使用 <strong>Ray</strong> 这个分布式框架来提交任务。</li>
<li><code>python3 -m recipe.dapo.main_dapo</code>：运行实际的 Python 训练代码。</li>
<li><strong>后面那一长串 <code>--</code> 开头的东西</strong>：<ul>
<li>那是把上面定义的变量（比如路径、并行度、学习率）全部传给 Python 程序。</li>
<li>例如 <code>algorithm.adv_estimator=${adv_estimator}</code> 就是告诉 Python 程序：“用 GRPO 算法”。</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr />
<h3>总结：这段代码到底在干啥？</h3>
<p>简单来说，这段代码在说：</p>
<blockquote>
<p>“嘿，Ray 集群！请帮我启动一个任务。
我们要用 <strong>16张 NPU 卡</strong>（<code>trainer.n_gpus_per_node=16</code>），
加载 <strong>Qwen3-30B MoE</strong> 这个大模型，
把模型切碎了放在不同的卡上（Megatron并行），
用 <strong>DAPO/GRPO</strong> 算法，
喂给它 <strong>数学竞赛题</strong> 数据，
让它学会如何更好地做数学题，
并且允许它输出很长的思考过程（20k tokens）。”</p>
</blockquote>
<p>你看不懂的主要原因是因为它混合了 <strong>Linux Shell 语法</strong>、<strong>Ray 分布式指令</strong>、<strong>Megatron 并行参数</strong> 和 <strong>强化学习超参</strong>。只要按上面的 Task 拆解，就能明白它只是一个复杂的“启动配置单”。</p>