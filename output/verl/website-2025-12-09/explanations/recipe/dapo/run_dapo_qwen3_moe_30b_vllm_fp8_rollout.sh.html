<h1>recipe/dapo/run_dapo_qwen3_moe_30b_vllm_fp8_rollout.sh</h1>
<p>这份脚本确实看起来很复杂，因为它包含了大量的<strong>超参数（Hyperparameters）</strong>和<strong>配置项</strong>。</p>
<p>简单来说，这是一个 <strong>启动脚本（Shell Script）</strong>，用于在多张显卡（GPU）上启动一个<strong>强化学习（RL）训练任务</strong>。</p>
<p>为了让你更容易理解，我们可以把这个脚本看作是给大模型“<strong>做一道复杂的菜（Recipe）</strong>”。我将用一个 <strong>Task List (任务清单)</strong> 的方式，一步步拆解它在做什么。</p>
<hr />
<h3>任务清单：训练大模型“Qwen3-30B”的强化学习之旅</h3>
<h4>✅ Task 1: 确定身份与目标 (基础设置)</h4>
<p><strong>“我们要训练谁？要做什么项目？”</strong></p>
<ul>
<li><strong>代码对应：</strong>
    <code>bash
    project_name='DAPO-FP8-ROLLOUT'
    exp_name='DAPO-Qwen3-MOE-30B-VLLM-FP8-ROLLOUT'
    MODEL_PATH="Qwen/Qwen3-30B-A3B-Base"</code></li>
<li><strong>解读：</strong><ul>
<li><strong>主角</strong>：Qwen3-30B-MoE（这是一个300亿参数的混合专家模型）。</li>
<li><strong>目标</strong>：DAPO（这是一种特定的强化学习算法或数据策略，通常用于提升推理能力）。</li>
<li><strong>特性</strong>：FP8 Rollout（指在生成文本时使用8位浮点数量化，为了省显存、跑得快）。</li>
</ul>
</li>
</ul>
<h4>✅ Task 2: 准备教材 (数据路径)</h4>
<p><strong>“用什么书来教它？考试考什么？”</strong></p>
<ul>
<li><strong>代码对应：</strong>
    <code>bash
    TRAIN_FILE=.../dapo-math-17k.parquet  # 训练教材：数学题
    TEST_FILE=.../aime-2024.parquet       # 考试卷子：AIME竞赛题</code></li>
<li><strong>解读：</strong><ul>
<li>这个模型将被训练去解数学题（Math），并用高难度的竞赛题（AIME）来测试效果。</li>
</ul>
</li>
</ul>
<h4>✅ Task 3: 制定教学大纲 (算法设置)</h4>
<p><strong>“用什么方法教？怎么奖罚分明？”</strong></p>
<ul>
<li><strong>代码对应：</strong>
    <code>bash
    adv_estimator=grpo      # 核心算法：GRPO (一种比PPO更省资源的算法)
    kl_coef=0.0             # 约束系数：这里设为0，意味着让模型放飞自我，不太限制它偏离原模型
    reward_model.reward_manager=dapo # 奖励机制：使用DAPO特定的奖励计算方式</code></li>
<li><strong>解读：</strong><ul>
<li>这里使用的是 <strong>GRPO (Group Relative Policy Optimization)</strong>。简单理解，它让模型对同一个问题生成多个答案，然后对比这些答案的好坏来学习，而不是只看一个。</li>
</ul>
</li>
</ul>
<h4>✅ Task 4: 设定课堂纪律 (长度与性能限制)</h4>
<p><strong>“一次能说多少话？显存不够怎么办？”</strong></p>
<ul>
<li><strong>代码对应：</strong>
    <code>bash
    max_prompt_length=1024        # 题目最长多长
    max_response_length=20480     # 回答最长多长 (20k tokens，允许很长的推理过程)
    rollout_is=token              # 修正策略
    +actor_rollout_ref.rollout.quantization=fp8 # 关键点：生成阶段用FP8量化</code></li>
<li><strong>解读：</strong><ul>
<li>允许模型进行非常长的思考（CoT，思维链），回答长度上限设得很高。</li>
<li><strong>FP8</strong> 是这个脚本的重点：在模型“尝试回答问题”（Rollout）的时候，把精度降低到FP8，这样速度极快且省显存，但需要一些特殊的参数（Correction parameters）来修正精度损失带来的误差。</li>
</ul>
</li>
</ul>
<h4>✅ Task 5: 召集算力资源 (环境配置)</h4>
<p><strong>“我们需要几台电脑？用什么引擎？”</strong></p>
<ul>
<li><strong>代码对应：</strong>
    <code>bash
    NNODES=2                      # 用2台服务器节点
    trainer.n_gpus_per_node=8     # 每台服务器8张卡（一共16张卡）
    actor_rollout_ref.rollout.name=vllm # 使用 vLLM 引擎来加速推理
    RAY_ADDRESS=...               # 使用 Ray 框架来管理分布式计算</code></li>
<li><strong>解读：</strong><ul>
<li>这是一个大规模训练，动用了16张显卡。</li>
<li>使用了 <strong>vLLM</strong>，这是目前最快的大模型推理引擎之一。</li>
<li>使用了 <strong>Ray</strong>，这是一个分布式计算框架，负责把任务分发给这16张卡。</li>
</ul>
</li>
</ul>
<h4>✅ Task 6: 正式开始上课 (执行命令)</h4>
<p><strong>“所有准备就绪，按下启动键！”</strong></p>
<ul>
<li><strong>代码对应：</strong>
    <code>bash
    ray job submit ... python3 -m recipe.dapo.main_dapo ...</code></li>
<li><strong>解读：</strong><ul>
<li>脚本最后这几百行的长命令，就是把上面定义的所有变量（比如学习率、Batch Size、路径等）打包传给 Python 程序 <code>main_dapo.py</code>，程序一旦运行，模型就开始训练了。</li>
</ul>
</li>
</ul>
<hr />
<h3>总结：这个脚本的核心逻辑</h3>
<p>如果你要向别人介绍这个脚本，你可以这样说：</p>
<blockquote>
<p>“这是一个使用 <strong>Ray</strong> 和 <strong>vLLM</strong> 框架的分布式训练脚本。</p>
<p>它的目的是对 <strong>Qwen3-30B MoE</strong> 模型进行 <strong>强化学习（GRPO算法）</strong> 微调。</p>
<p>它的特点是使用了 <strong>FP8 量化推理</strong> 来加速生成过程，并针对数学任务（DAPO Math）进行了长文本（20k context）的优化设置。”</p>
</blockquote>
<h3>你可能遇到的困惑点（Q&amp;A）</h3>
<ol>
<li>
<p><strong>为什么会有 <code>actor</code>, <code>rollout</code>, <code>ref</code> 这三个词？</strong></p>
<ul>
<li>这是强化学习（PPO/GRPO）的标准架构：</li>
<li><strong>Actor (演员)</strong>：正在学习的模型，负责输出答案。</li>
<li><strong>Rollout (采样)</strong>：负责根据 Actor 的策略快速生成大量数据（这里用了 vLLM + FP8 加速）。</li>
<li><strong>Ref (参考)</strong>：原始模型，用来对比 Actor 跑偏了没有（防止模型为了拿高分而胡言乱语）。</li>
</ul>
</li>
<li>
<p><strong><code>set -xeuo pipefail</code> 是啥？</strong></p>
<ul>
<li>这是 Bash 脚本的“安全带”。如果脚本里任何一行命令报错了，整个脚本立刻停止，防止错误的命令继续执行导致灾难。</li>
</ul>
</li>
<li>
<p><strong><code>clip_ratio</code> 和 <code>temperature</code> 是啥？</strong></p>
<ul>
<li><strong>Clip Ratio</strong>：防止模型一次性更新步子迈得太大，扯着蛋（训练崩溃）。</li>
<li><strong>Temperature</strong>：控制模型生成的随机性。1.0 表示比较有创造力，0 表示完全死板。</li>
</ul>
</li>
</ol>
<p>希望这个 List 能帮你理清思路！如果需要对某一个具体参数（比如 <code>sp_size</code> 或 <code>offload</code>）做深入解释，可以随时问我。</p>