<h1>recipe/r1/run_r1_distill_qwen.sh</h1>
<p>完全没问题。这段代码其实就是一个<strong>自动化“考试”脚本</strong>。</p>
<p>它的核心目的是：<strong>拿一个特定的 AI 模型（DeepSeek-R1-Distill-Qwen），给它做一套卷子（数据集），然后给它的答案打分。</strong></p>
<p>我们可以把这个脚本拆解成一个 <strong>“三步走”的 To-Do List</strong>。你可以把自己想象成这场考试的监考老师，我们需要按顺序完成以下任务：</p>
<hr />
<h3>📋 任务清单 (To-Do List)</h3>
<ol>
<li><strong>准备考卷</strong> (Data Process)：把原始的题目整理好，放在指定位置。</li>
<li><strong>进行考试</strong> (Generation)：让模型进入考场，针对题目写出答案（而且每道题要写 8 个不同版本的答案）。</li>
<li><strong>批改打分</strong> (Evaluation)：拿标准答案和评分规则，给模型写的答案打分。</li>
</ol>
<hr />
<h3>🔍 逐步详细讲解</h3>
<p>下面我们结合代码，一步一步把上面的清单落实。</p>
<h4>0. 考前配置 (定义变量)</h4>
<p>在开始任务前，脚本先定义了“谁来考试”和“在哪考试”。</p>
<div class="codehilite"><pre><span></span><code><span class="nv">MODEL_PATH</span><span class="o">=</span>Qwen/DeepSeek-R1-Distill-Qwen-1.5B
<span class="nv">DATA_PATH</span><span class="o">=</span>/workspace/datasets/r1_bench
</code></pre></div>

<ul>
<li><strong>MODEL_PATH</strong>: 指定了考生是谁。这里选的是 <code>DeepSeek-R1-Distill-Qwen-1.5B</code> 这个模型。</li>
<li><strong>DATA_PATH</strong>: 指定了考场和卷子在哪。数据存放在 <code>/workspace/datasets/r1_bench</code>。</li>
</ul>
<hr />
<h4>✅ 任务 1：准备考卷 (Eval Data Process)</h4>
<div class="codehilite"><pre><span></span><code>python3<span class="w"> </span>-m<span class="w"> </span>recipe.r1.data_process<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--local_dir<span class="w"> </span><span class="nv">$DATA_PATH</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--tasks<span class="w"> </span>all
</code></pre></div>

<ul>
<li><strong>你在做什么</strong>：运行一个数据处理程序。</li>
<li><strong>通俗解释</strong>：这就像是从题库里把题目下载下来，打印成模型能看懂的“试卷格式”，然后存到 <code>DATA_PATH</code> 文件夹里。</li>
<li><code>--tasks all</code>：意思是“所有科目的题都要考”（比如数学、代码、逻辑等所有任务）。</li>
</ul>
<hr />
<h4>✅ 任务 2：进行考试 (Generation)</h4>
<p>这是最长、最复杂的一步，因为要配置考场的规则。</p>
<div class="codehilite"><pre><span></span><code>python3<span class="w"> </span>-m<span class="w"> </span>verl.trainer.main_generation<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>trainer.nnodes<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>trainer.n_gpus_per_node<span class="o">=</span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>data.path<span class="o">=</span><span class="nv">$DATA_PATH</span>/test.parquet<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>...<span class="w"> </span><span class="o">(</span>省略中间参数<span class="o">)</span><span class="w"> </span>...
<span class="w">    </span>rollout.response_length<span class="o">=</span><span class="m">32768</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>...
</code></pre></div>

<ul>
<li><strong>你在做什么</strong>：启动 <code>verl</code> 这个框架的生成器，让模型开始做题。</li>
<li><strong>关键参数解读</strong>：<ul>
<li><code>trainer.n_gpus_per_node=8</code>：<strong>动用算力</strong>。这场考试需要 8 张显卡并行工作，速度才够快。</li>
<li><code>data.path=.../test.parquet</code>：<strong>发卷子</strong>。读取刚才任务1里准备好的测试题。</li>
<li><code>data.n_samples=8</code>：<strong>题海战术</strong>。对于每一道题，要求模型生成 <strong>8 个不同的答案</strong>。为什么要这么做？为了测试模型的稳定性（比如看 8 次里能对几次，或者做“多数投票”）。</li>
<li><code>rollout.temperature=0.6</code>：<strong>思维活跃度</strong>。0.6 代表让模型稍微有点创造力，不要太死板，但也不要胡言乱语。</li>
<li><code>rollout.response_length=32768</code>：<strong>允许写长文</strong>。R1 系列模型擅长“深度思考”（Chain of Thought），这个参数允许它写非常长的推理过程（最多 32k tokens）。</li>
<li><code>data.output_path=.../test-output-8.parquet</code>：<strong>交卷</strong>。把模型生成的这 8 份答案保存下来。</li>
</ul>
</li>
</ul>
<hr />
<h4>✅ 任务 3：批改打分 (Evaluation)</h4>
<div class="codehilite"><pre><span></span><code>python3<span class="w"> </span>-m<span class="w"> </span>recipe.r1.main_eval<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>data.path<span class="o">=</span><span class="nv">$DATA_PATH</span>/test-output-8.parquet<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>data.prompt_key<span class="o">=</span>prompt<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>data.response_key<span class="o">=</span>responses<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>custom_reward_function.path<span class="o">=</span>recipe/r1/reward_score.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>custom_reward_function.name<span class="o">=</span>reward_func
</code></pre></div>

<ul>
<li><strong>你在做什么</strong>：运行评估程序。</li>
<li><strong>通俗解释</strong>：<ul>
<li><code>data.path</code>：老师拿起了刚才模型交上来的卷子（<code>test-output-8.parquet</code>）。</li>
<li><code>custom_reward_function</code>：老师拿出了<strong>评分标准</strong>。这里用了一个自定义的 Python 脚本 (<code>reward_score.py</code>) 来判断答案对不对。</li>
<li>最终，这一步会输出一个分数，告诉你这个模型在这个数据集上表现如何（比如准确率是多少）。</li>
</ul>
</li>
</ul>
<hr />
<h3>💡 总结</h3>
<p>这个脚本讲了一个完整的故事：
1.  <strong>准备数据</strong> (Data Process)
2.  <strong>让模型疯狂做题，每题做8遍</strong> (Generation)
3.  <strong>算算它到底考了多少分</strong> (Evaluation)</p>
<p>现在再看那个文件，是不是清晰多了？</p>