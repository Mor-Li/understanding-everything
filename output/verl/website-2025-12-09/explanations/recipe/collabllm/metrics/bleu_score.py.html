<h1>recipe/collabllm/metrics/bleu_score.py</h1>
<p>这份代码乍一看有点吓人，主要是因为那个很长的字符串（Prompt）占了很大篇幅。</p>
<p>简单来说，这是一个<strong>“自动阅卷脚本”</strong>。它的作用是给大模型生成的<strong>多轮对话</strong>质量打分。</p>
<p>为了让你彻底搞懂，我为你列了一个由浅入深的 <strong>学习任务清单 (To-Do List)</strong>。我们可以按照这个顺序一步步拆解：</p>
<hr />
<h3>📋 学习任务清单 (To-Do List)</h3>
<ul>
<li><strong>Task 1: 搞懂核心场景</strong> —— 为什么要写这个代码？</li>
<li><strong>Task 2: 理解核心难题</strong> —— 为什么不能直接打分，非要搞这么复杂？</li>
<li><strong>Task 3: 拆解解决方案</strong> —— 那个很长的英文 Prompt 是干嘛的？</li>
<li><strong>Task 4: 了解评分标准</strong> —— 什么是 BLEU 分数？</li>
<li><strong>Task 5: 串联代码逻辑</strong> —— 这一步步在代码里是怎么发生的？</li>
</ul>
<hr />
<h3>💡 逐步讲解</h3>
<h4>Task 1: 搞懂核心场景</h4>
<p>想象你是一个老师，你要给一个学生（AI）打分。
*   <strong>题目（Task）：</strong> 比如“帮我写一篇关于环保的文章”。
*   <strong>标准答案（Ground Truth）：</strong> 老师手里有一篇满分作文。
*   <strong>学生表现（Messages）：</strong> 学生（AI）和用户聊了十句，中间修改了好几次，最后才写完。</p>
<p>这个文件的目的就是：<strong>拿学生的表现和标准答案比对，算出一个分数。</strong></p>
<h4>Task 2: 理解核心难题</h4>
<p>为什么这事儿难办？
因为学生的表现是<strong>“多轮对话”</strong>。
*   用户说：写个开头。 AI：写好了...
*   用户说：再写个结尾。 AI：写好了...
*   用户说：把中间改改。 AI：改好了...</p>
<p>如果你直接拿这<strong>一长串乱七八糟的聊天记录</strong>去和<strong>标准答案（只有一篇干净的文章）</strong>做对比，分数肯定很低，因为聊天记录里废话太多了。</p>
<p><strong>结论：</strong> 我们需要先把聊天记录里的“最终成品”提取出来。</p>
<h4>Task 3: 拆解解决方案（那个很长的 Prompt）</h4>
<p>代码里那个叫 <code>EXTRACT_MULTITURN_COMPLETION_PROMPT</code> 的长字符串，其实是写给<strong>另一个AI（助教）</strong>的指令。</p>
<p>这段指令的意思是：</p>
<blockquote>
<p>“你是一个认真的分析员。我会给你一段用户和AI的<strong>多轮聊天记录</strong>。请你帮我把AI在最后生成的、最完整的、修改后的<strong>最终文档</strong>提取出来。不要聊天的废话，只要最终结果。”</p>
</blockquote>
<p><strong>代码行为：</strong>
程序会先把聊天记录发给这个“助教AI”，让它把最终答案整理成一个干净的 JSON 格式（包含思考过程 <code>thought</code> 和最终内容 <code>final_completion</code>）。</p>
<h4>Task 4: 了解评分标准 (BLEU Score)</h4>
<p>提取出干净的“最终内容”后，怎么打分？
代码用的是 <strong>BLEU</strong> 算法（<code>from nltk.translate.bleu_score import sentence_bleu</code>）。</p>
<ul>
<li><strong>BLEU 是什么？</strong> 它是机器翻译界最常用的指标。</li>
<li><strong>原理：</strong> 简单的“找相同”。它看“学生生成的句子”里有多少词汇/短语是出现在“标准答案”里的。重合度越高，分数越高。</li>
</ul>
<h4>Task 5: 串联代码逻辑 (Walkthrough)</h4>
<p>现在回到代码函数 <code>async def compute_score(...)</code>，我们按行来看它做了什么：</p>
<ol>
<li>
<p><strong>准备工具：</strong></p>
<ul>
<li>检查有没有 <code>litellm</code> 库，没有就用 <code>openai</code> 库。这俩都是用来调用大模型接口的工具。</li>
</ul>
</li>
<li>
<p><strong>整理输入：</strong></p>
<ul>
<li><code>chat_history = parse_messages(...)</code>: 把乱七八糟的聊天记录格式化成字符串。</li>
<li><code>prompt = ...format(...)</code>: 把聊天记录塞进那个“助教指令”里。</li>
</ul>
</li>
<li>
<p><strong>召唤助教 (AI调用)：</strong></p>
<ul>
<li><code>await litellm.acompletion(...)</code> 或 <code>client.chat.completions.create(...)</code>:</li>
<li><strong>这一步很关键！</strong> 它调用了一个大模型，把刚才整理好的指令发过去。目的是让大模型帮我们<strong>提取</strong>出聊天中的最终答案。</li>
</ul>
</li>
<li>
<p><strong>解析助教的回答：</strong></p>
<ul>
<li><code>full_response = extract_json(full_response)</code>: 把助教AI返回的文字转成字典格式。</li>
<li><code>assert ...</code>: 检查一下格式对不对，必须包含 <code>final_completion</code>（最终内容）和 <code>thought</code>（思考过程）。</li>
<li><code>final_completion = full_response.pop("final_completion")</code>: 拿到了！这就是我们要评分的对象。</li>
</ul>
</li>
<li>
<p><strong>打分并返回：</strong></p>
<ul>
<li><code>bleu = sentence_bleu([ground_truth], final_completion)</code>:</li>
<li>左手拿着<strong>标准答案</strong> (<code>ground_truth</code>)，右手拿着刚才提取的<strong>最终内容</strong> (<code>final_completion</code>)，计算相似度。</li>
<li><code>return float(bleu)</code>: 返回最终分数。</li>
</ul>
</li>
</ol>
<hr />
<h3>📝 总结</h3>
<p>这个脚本讲了一个“<strong>先整理，后打分</strong>”的故事：</p>
<ol>
<li>因为它知道<strong>多轮对话</strong>很乱，没法直接评测。</li>
<li>所以它先写了一段 Prompt，<strong>调用一个 LLM</strong> 去把对话里的“最终干货”提取出来。</li>
<li>最后拿这个“干货”和“标准答案”对比，算出 <strong>BLEU 分数</strong>。</li>
</ol>