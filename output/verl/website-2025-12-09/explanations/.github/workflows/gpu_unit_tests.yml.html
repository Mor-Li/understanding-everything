<h1>.github/workflows/gpu_unit_tests.yml</h1>
<p>完全没问题。这个 YAML 文件其实是一个 <strong>自动化脚本（CI/CD Workflow）</strong>。</p>
<p>你可以把它想象成一个<strong>“机器人管家”</strong>。每当你（或者其他开发者）修改了代码，这个管家就会拿出一张<strong>“任务清单（To-Do List）”</strong>，一步一步地去执行，目的是<strong>检查代码有没有改坏</strong>，特别是涉及到 GPU 运行的部分。</p>
<p>下面我把这个文件拆解成一个通俗易懂的 <strong>Task To-Do List</strong>，带你走一遍它的逻辑：</p>
<hr />
<h3>第一阶段：阅读“家规”（文件开头的注释部分）</h3>
<p><em>管家在干活前，先复习了一下项目里的测试规则。</em></p>
<ol>
<li><strong>[了解地图]</strong>：<ul>
<li>所有的测试代码都在 <code>tests/</code> 文件夹里。</li>
<li><code>tests/trainer</code> 测训练功能，<code>tests/models</code> 测模型功能。</li>
</ul>
</li>
<li><strong>[识别特殊区域]</strong>：<ul>
<li>有些文件夹叫 <code>special_...</code>，那是特殊测试（比如需要多卡 GPU、或者是端到端测试）。</li>
</ul>
</li>
<li><strong>[区分 CPU 和 GPU]</strong>：<ul>
<li>文件名如果以 <code>_on_cpu.py</code> 结尾，就只用 CPU 测。</li>
<li><strong>重点</strong>：其他的默认都要用 GPU 测（这正是本文件的核心任务）。</li>
</ul>
</li>
</ol>
<hr />
<h3>第二阶段：蹲点守候（<code>on:</code> 部分）</h3>
<p><em>管家坐在门口，盯着代码仓库的动静。</em></p>
<ol>
<li><strong>[监控触发条件]</strong>：<ul>
<li><strong>事件</strong>：有人 <code>push</code>（提交代码）或者提了 <code>pull_request</code>（合并请求）。</li>
<li><strong>目标分支</strong>：只关心 <code>main</code> 分支或 <code>v0.4.x</code> 分支。</li>
</ul>
</li>
<li><strong>[过滤无效干扰]</strong>：<ul>
<li>如果修改的文件<strong>不包含</strong> Python 代码（<code>**/*.py</code>），管家不干活。</li>
<li>如果修改的只是 <code>examples/</code>（例子）、<code>recipe/</code>（配方）或者明确是 CPU 的测试文件（<code>*_on_cpu.py</code>），管家也不干活（因为有别的管家负责那些）。</li>
<li><strong>只有</strong>修改了核心代码或 GPU 测试文件时，管家才启动。</li>
</ul>
</li>
</ol>
<hr />
<h3>第三阶段：准备工作环境（<code>jobs: setup</code> 部分）</h3>
<p><em>管家发现有活干了，但他需要一台带 GPU 的电脑。</em></p>
<ol>
<li><strong>[申请机器]</strong>：<ul>
<li>调用接口（<code>volcengine</code>，火山引擎），申请一台临时的云服务器（Runner）。</li>
<li>这就好比去网吧开了一台带强力显卡的主机。</li>
</ul>
</li>
</ol>
<hr />
<h3>第四阶段：正式干活（<code>jobs: gpu_unit_tests</code> 部分）</h3>
<p><em>管家坐到了这台刚申请好的 GPU 电脑前，开始按清单操作。</em></p>
<ol>
<li><strong>[下载代码]</strong>：<ul>
<li>把仓库里最新的代码下载到这台机器上（<code>checkout</code>）。</li>
</ul>
</li>
<li><strong>[安装环境]</strong>：<ul>
<li>安装 Python 依赖包（<code>pip install ...</code>）。</li>
<li>安装 PyTorch、CUDA 相关的库，确保环境能跑深度学习代码。</li>
</ul>
</li>
<li><strong>[执行任务 A：通用 GPU 测试]</strong>：<ul>
<li><strong>动作</strong>：运行 <code>pytest</code>（Python 的测试工具）。</li>
<li><strong>细节</strong>：管家非常小心，他<strong>排除</strong>（ignore）了很多东西：<ul>
<li>不测 CPU 的代码。</li>
<li>不测 <code>vllm</code> 和 <code>sglang</code> 相关的（可能太重了，有专门的测试测它们）。</li>
<li>不测 <code>tests/models</code> 里的（可能有专门的 <code>model.yml</code> 测）。</li>
</ul>
</li>
<li><strong>目的</strong>：只跑那些核心的、轻量级的 GPU 单元测试。</li>
</ul>
</li>
<li><strong>[执行任务 B：特殊的分布式测试]</strong>：<ul>
<li><strong>动作</strong>：运行 <code>torchrun</code>（PyTorch 的分布式运行工具）。</li>
<li><strong>测试 1</strong>：测 <code>LinearCrossEntropyTP</code>（一种并行计算的损失函数），看看算得对不对，显存占用正不正常。</li>
<li><strong>测试 2</strong>：模拟 2 张显卡，测试 FSDP2 的 Actor（强化学习里的“演员”模型）功能。</li>
<li><strong>测试 3</strong>：模拟 2 张显卡，测试 FSDP2 的 Critic（强化学习里的“评论家”模型）功能。</li>
</ul>
</li>
</ol>
<hr />
<h3>第五阶段：打扫战场（<code>jobs: cleanup</code> 部分）</h3>
<p><em>活干完了（不管成功还是失败），管家要退房。</em></p>
<ol>
<li><strong>[归还机器]</strong>：<ul>
<li>调用接口，把刚才申请的那台云服务器销毁（<code>destroy</code>）。</li>
<li><strong>目的</strong>：省钱，不能让机器一直空转扣费。</li>
</ul>
</li>
</ol>
<hr />
<h3>总结</h3>
<p>这个文件的核心逻辑就是：
<strong>“只要有人改了核心代码，就自动租一台 GPU 服务器，跑一遍核心的 GPU 单元测试和几个关键的分布式训练组件测试，跑完把服务器退了。”</strong></p>