<h1>.github/workflows/reward_model_vllm.yml</h1>
<p>这份文件是一个 <strong>GitHub Actions 的自动化工作流配置文件</strong>。简单来说，它是一份写给 GitHub 的“机器人指令书”。</p>
<p>它的主要目的是：<strong>当有人修改代码时，自动租一台带 GPU 的云服务器，测试一下“奖励模型（Reward Model）”相关的代码有没有被改坏。</strong></p>
<p>为了让你好理解，我把你当作这个“自动化机器人”，给你列一份 <strong>To-Do List (任务清单)</strong>，我们一步步来执行这份文件：</p>
<hr />
<h3>🤖 机器人的任务清单 (To-Do List)</h3>
<h4>第一阶段：阅读“员工手册” (文件顶部的注释)</h4>
<p><em>这部分是写给人看的注释（# 开头），机器其实不执行，但它告诉了开发者这个项目的规则。</em></p>
<ol>
<li><strong>了解测试分类规则</strong>：<ul>
<li><code>tests/</code> 目录下的文件夹对应不同的模块（比如 <code>trainer</code>, <code>models</code>）。</li>
<li><code>special_</code> 开头的文件夹是特殊测试（比如需要多卡 GPU 的，或者只在 NPU 上跑的）。</li>
</ul>
</li>
<li><strong>了解硬件分配规则</strong>：<ul>
<li>默认情况下，测试都在 <strong>GPU</strong> 上跑。</li>
<li>除非文件名以此结尾：<code>_on_cpu.py</code>（这种只在 CPU 上跑）。</li>
</ul>
</li>
<li><strong>了解工作流布局</strong>：<ul>
<li>有些测试是每次必跑的（轻量级）。</li>
<li>有些是重型测试（比如这个文件），涉及多 GPU。</li>
</ul>
</li>
</ol>
<hr />
<h4>第二阶段：待命与触发 (Trigger)</h4>
<p><em>这是代码中的 <code>on:</code> 部分。</em></p>
<ol>
<li><strong>监听触发信号</strong>：<ul>
<li><strong>如果是 Push (推送代码)</strong>：只监听 <code>main</code> 分支或 <code>v0.*</code> 版本分支。</li>
<li><strong>如果是 Pull Request (提交合并请求)</strong>：<ul>
<li>目标分支是 <code>main</code> 或 <code>v0.*</code>。</li>
<li><strong>并且</strong> 修改的文件必须涉及 <code>verl/**/*.py</code> (核心代码) 或者 <code>tests/experimental/reward/**</code> (奖励模型测试代码)。</li>
</ul>
</li>
<li><em>如果不满足上述条件，机器人继续睡觉，不执行后续任务。</em></li>
</ul>
</li>
</ol>
<hr />
<h4>第三阶段：准备干活的环境 (Job: setup)</h4>
<p><em>这是代码中的 <code>jobs: setup</code> 部分。</em></p>
<ol>
<li><strong>检查权限</strong>：确认仓库拥有者是 <code>volcengine</code>（火山引擎）。</li>
<li><strong>租借计算资源</strong>：<ul>
<li>向云端（Volcengine）申请一台高性能服务器。</li>
<li>镜像（Image）使用：<code>verl:vllm011.dev7</code> (预装好了环境)。</li>
<li>拿到这台机器的 ID 和标签（Label），准备给后面的任务用。</li>
</ul>
</li>
</ol>
<hr />
<h4>第四阶段：执行核心测试 (Job: reward_model_vllm)</h4>
<p><em>这是代码中的 <code>jobs: reward_model_vllm</code> 部分，也是最核心的步骤。</em></p>
<ol>
<li><strong>登录机器</strong>：使用刚才申请到的那台带 8 张 L20 GPU 的服务器。</li>
<li><strong>设置网络环境</strong>：配置代理（Proxy），确保能连上 HuggingFace 镜像站下载模型，关掉一些不必要的检查。</li>
<li><strong>下载代码</strong> (<code>actions/checkout</code>)：把当前的 GitHub 代码仓库下载到这台服务器上。</li>
<li><strong>安装软件</strong> (<code>pip install</code>)：安装当前项目及其测试依赖。</li>
<li><strong>准备数据</strong> (<code>Prepare gsm8k dataset</code>)：<ul>
<li>清理旧进程。</li>
<li>下载并处理 <code>gsm8k</code> 数据集（这是一个常用的数学推理数据集）。</li>
</ul>
</li>
<li><strong>开始跑测试 (关键步骤)</strong>：<ul>
<li><strong>测试 1 (生成式奖励模型)</strong>：运行 <code>test_reward_model_genrm.py</code>。测试模型能不能生成正确的奖励评分。</li>
<li><strong>测试 2 (判别式奖励模型)</strong>：运行 <code>test_reward_model_disrm.py</code>。测试模型能不能分辨好坏。</li>
<li><strong>测试 3 (Agent 循环)</strong>：运行 <code>test_agent_loop_reward_manager.py</code>。测试智能体（Agent）和奖励管理器配合的循环是否正常。</li>
<li><strong>测试 4 (联合部署)</strong>：运行 <code>test_agent_reward_loop_colocate.py</code>。测试把 Agent 和奖励模型放在一起跑（Colocate）是否正常。</li>
<li><em>注：这些测试都使用了 <code>vllm</code> (一个加速推理的库) 作为后端。</em></li>
</ul>
</li>
</ol>
<hr />
<h4>第五阶段：打扫战场 (Job: cleanup)</h4>
<p><em>这是代码中的 <code>jobs: cleanup</code> 部分。</em></p>
<ol>
<li><strong>归还机器</strong>：<ul>
<li>不管前面的测试是成功还是失败 (<code>if: always()</code>)，都要执行这一步。</li>
<li>通知云端销毁刚才申请的服务器，停止计费。</li>
</ul>
</li>
</ol>
<hr />
<h3>总结</h3>
<p>这份文件的核心逻辑就是：
<strong>“只要有人改了代码，就去租一台 8 卡 GPU 的服务器，用 vllm 加速框架把 4 个关于奖励模型（Reward Model）的关键测试跑一遍，跑完记得把服务器退了。”</strong></p>