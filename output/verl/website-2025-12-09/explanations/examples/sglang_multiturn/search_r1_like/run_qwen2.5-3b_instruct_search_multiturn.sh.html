<h1>examples/sglang_multiturn/search_r1_like/run_qwen2.5-3b_instruct_search_multiturn.sh</h1>
<p>这份脚本（Shell Script）实际上是一个<strong>启动“AI 训练任务”的命令清单</strong>。</p>
<p>简单来说，它的目的是：<strong>教一个叫 Qwen2.5-3B 的模型，学会使用搜索引擎（Search Tool）进行多轮对话，来解决复杂问题。</strong></p>
<p>为了让你听懂，我把这个脚本拆解成一个 <strong>“项目经理发布的任务清单（To-Do List）”</strong>，我们一步步来看它到底在安排什么工作。</p>
<hr />
<h3>📋 任务清单：训练“会搜索的 AI”</h3>
<h4>✅ Task 1: 准备工作环境 (Setup)</h4>
<p><strong>脚本内容：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># run on 8xH20 (注释：指明硬件需求)</span>
<span class="nb">set</span><span class="w"> </span>-x<span class="w">  </span><span class="o">(</span>开启调试模式，打印每行命令<span class="o">)</span>
<span class="nb">ulimit</span><span class="w"> </span>-n<span class="w"> </span><span class="m">65535</span><span class="w"> </span><span class="o">(</span>放开系统文件限制，防止报错<span class="o">)</span>
<span class="nv">PROJECT_DIR</span><span class="o">=</span><span class="s2">&quot;</span><span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span><span class="s2">&quot;</span><span class="w"> </span>...<span class="w"> </span><span class="o">(</span>定义各个文件夹路径<span class="o">)</span>
<span class="nv">TRAIN_DATA</span><span class="o">=</span>...<span class="w"> </span><span class="o">(</span>定义训练教材在哪里<span class="o">)</span>
<span class="nv">TOOL_CONFIG</span><span class="o">=</span>...<span class="w"> </span><span class="o">(</span>定义搜索工具的配置文件<span class="o">)</span>
</code></pre></div>

<p><strong>解读：</strong>
就像做菜前要备菜一样。这里是在告诉电脑：
1.  我们的根目录在哪里。
2.  <strong>教材（数据）</strong>在哪里（<code>train.parquet</code>）。
3.  <strong>工具箱</strong>在哪里（<code>search_tool_config.yaml</code>，这是告诉 AI 怎么用搜索引擎的说明书）。</p>
<h4>✅ Task 2: 选定“学生”和“老师” (Model &amp; Algorithm)</h4>
<p><strong>脚本内容：</strong></p>
<div class="codehilite"><pre><span></span><code>python3<span class="w"> </span>-m<span class="w"> </span>verl.trainer.main_ppo<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>algorithm.adv_estimator<span class="o">=</span>grpo<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>actor_rollout_ref.model.path<span class="o">=</span>Qwen/Qwen2.5-3B-Instruct<span class="w"> </span><span class="se">\</span>
</code></pre></div>

<p><strong>解读：</strong>
*   <strong>学生是谁？</strong> <code>Qwen2.5-3B-Instruct</code>。这是一个通义千问的中等大小模型。
*   <strong>用什么教学法？</strong> <code>main_ppo</code> 和 <code>grpo</code>。
    *   <strong>PPO/GRPO</strong> 是强化学习（Reinforcement Learning）算法。
    *   <strong>通俗理解：</strong> 我们不是直接把答案塞给它（那是微调），而是让它尝试回答，答得好给糖吃（奖励），答得烂扣分。GRPO 是 DeepSeek-R1 背后使用的高效训练方法。</p>
<h4>✅ Task 3: 设定“考试规则”——多轮搜索 (Multi-turn &amp; Tools)</h4>
<p><strong>脚本内容：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="w">    </span>actor_rollout_ref.rollout.multi_turn.max_assistant_turns<span class="o">=</span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>actor_rollout_ref.rollout.multi_turn.tool_config_path<span class="o">=</span><span class="s2">&quot;</span><span class="nv">$TOOL_CONFIG</span><span class="s2">&quot;</span><span class="w"> </span><span class="se">\</span>
</code></pre></div>

<p><strong>解读：</strong>
这是这个脚本<strong>最核心</strong>的地方！
*   <strong>Tool Config:</strong> 允许模型使用工具（这里特指搜索引擎）。
*   <strong>Multi-turn (多轮):</strong> 允许模型进行多轮思考。
*   <strong>场景模拟：</strong> 用户问一个难题 -&gt; 模型觉得不知道 -&gt; 模型决定调用搜索工具 -&gt; 拿到搜索结果 -&gt; 模型根据结果再次思考 -&gt; 最终回答。
*   <code>max_assistant_turns=2</code>: 限制它最多只能在这个过程中交互/思考 2 轮，防止它无限搜索下去。</p>
<h4>✅ Task 4: 配置“加速引擎” (Inference Engine)</h4>
<p><strong>脚本内容：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="w">    </span>actor_rollout_ref.rollout.name<span class="o">=</span>sglang<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>actor_rollout_ref.rollout.tensor_model_parallel_size<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
</code></pre></div>

<p><strong>解读：</strong>
*   <strong>SGLang:</strong> 这是一个非常快的推理引擎（让模型生成文字速度变快）。
*   在强化学习中，模型需要自己生成很多个答案来让老师打分，这个过程叫 Rollout。用 <code>sglang</code> 是为了让这个生成过程飞快，节省训练时间。</p>
<h4>✅ Task 5: 设定“奖惩标准” (Hyperparameters)</h4>
<p><strong>脚本内容：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="w">    </span>data.train_batch_size<span class="o">=</span><span class="m">512</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>actor_rollout_ref.actor.optim.lr<span class="o">=</span>1e-6<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>actor_rollout_ref.actor.kl_loss_coef<span class="o">=</span><span class="m">0</span>.001<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>actor_rollout_ref.rollout.n<span class="o">=</span><span class="m">5</span><span class="w"> </span><span class="se">\</span>
</code></pre></div>

<p><strong>解读：</strong>
*   <code>lr=1e-6</code>: 学习率。意思是“步子迈小点，慢慢学”，防止学歪了。
*   <code>rollout.n=5</code>: 针对同一个问题，让模型尝试生成 <strong>5 种</strong> 不同的解法，然后从中挑最好的来学习。
*   <code>kl_loss_coef</code>: 这是一个“紧箍咒”。防止模型为了拿高分，说话变得语无伦次，强迫它保持原本的语言能力。</p>
<h4>✅ Task 6: 硬件分配与日志 (Hardware &amp; Logging)</h4>
<p><strong>脚本内容：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="w">    </span>trainer.n_gpus_per_node<span class="o">=</span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>trainer.project_name<span class="o">=</span><span class="s1">&#39;search_r1_like_async_rl&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>trainer.experiment_name<span class="o">=</span><span class="s1">&#39;...&#39;</span><span class="w"> </span><span class="se">\</span>
</code></pre></div>

<p><strong>解读：</strong>
*   <strong>用了几张卡？</strong> 8 张 GPU（<code>8xH20</code> 指的是 H20 型号的显卡）。
*   <strong>项目叫什么？</strong> <code>search_r1_like</code>。这暗示了这个项目是想复现 <strong>DeepSeek-R1</strong> 那种具备推理和搜索能力的模型。
*   <strong>日志：</strong> 训练过程会被记录下来，方便人类随时查看进度。</p>
<hr />
<h3>总结：这段代码在干嘛？</h3>
<p>如果把训练 AI 比作<strong>特训一个实习生</strong>，这个脚本就是在说：</p>
<blockquote>
<p>“嘿，电脑！请帮我启动一个特训班。</p>
<ol>
<li><strong>实习生（模型）</strong>是 Qwen2.5-3B。</li>
<li><strong>教材（数据）</strong>在指定文件夹。</li>
<li><strong>训练目标</strong>：学会使用<strong>搜索引擎</strong>来回答问题。</li>
<li><strong>训练方式</strong>：给它一个问题，让它尝试用搜索工具找答案（最多搜 2 轮），它会试 5 种不同的搜索思路。</li>
<li><strong>评价标准</strong>：用 GRPO 算法，搜得准、答得对就奖励。</li>
<li><strong>装备</strong>：用 SGLang 加速引擎，动用 8 张显卡全速跑！”</li>
</ol>
</blockquote>
<p><strong>一句话概括：</strong> 这是一个使用 8 张显卡，通过强化学习（GRPO），训练 Qwen 模型学会<strong>多轮搜索</strong>能力的启动脚本。</p>