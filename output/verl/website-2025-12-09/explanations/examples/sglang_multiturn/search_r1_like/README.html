<h1>examples/sglang_multiturn/search_r1_like</h1>
<p>这是一个非常前沿的实战目录。简单来说，这个文件夹是一个<strong>“DeepSeek-R1 复刻训练营”</strong>的启动包。</p>
<p>它的核心目的是：<strong>教一个普通的开源模型（Qwen2.5），学会像 DeepSeek-R1 那样，遇到难题时懂得自己去“搜索”资料，经过多轮思考，最后给出答案。</strong></p>
<p>下面我用通俗的比喻来拆解：</p>
<h3>1. 这个文件夹主要负责什么功能？</h3>
<p><strong>核心功能：训练“会查资料”的 AI。</strong></p>
<p>如果把 AI 模型比作一个<strong>学生</strong>：
*   <strong>以前的训练</strong>：是“填鸭式教育”。把书本背下来，考试时靠记忆回答。如果没背过，就瞎编。
*   <strong>这个文件夹的训练</strong>：是<strong>“研究能力特训”</strong>。
    *   给学生一个难题。
    *   允许学生使用<strong>搜索引擎</strong>（Search Tool）。
    *   学生可以查资料、读资料、再思考、再查（多轮 Multiturn）。
    *   如果查得好、答对了，就给奖励（强化学习）。</p>
<p>这个目录就是用来启动这个“特训”过程的。</p>
<hr />
<h3>2. 各个文件/子文件夹分别是干什么的？</h3>
<p>这里主要有两个核心部分，我们用<strong>“特训班”</strong>的角色来比喻：</p>
<h4>📄 <code>run_qwen2.5-3b_instruct_search_multiturn.sh</code></h4>
<p><strong>角色：特训班的“总教官”与“课程表”</strong></p>
<p>这是一份启动脚本，它安排了所有的训练细节：
*   <strong>指定学员</strong>：<code>Qwen/Qwen2.5-3B-Instruct</code>（我们要训练这个模型）。
*   <strong>指定教学法</strong>：<code>GRPO</code>（这是 DeepSeek-R1 背后的核心算法，一种高效的强化学习方法）。
*   <strong>指定考核方式</strong>：<code>multi_turn</code>（允许你多轮查资料，最多查 2 次），<code>rollout.n=5</code>（同一个问题试 5 种不同的解法，挑最好的学）。
*   <strong>指定硬件</strong>：调用 8 张显卡全速运转。</p>
<p><strong>一句话</strong>：只要运行这个脚本，电脑就开始疯狂训练 AI 学会搜索了。</p>
<h4>📁 <code>local_dense_retriever/</code></h4>
<p><strong>角色：特训班专用的“模拟图书馆”</strong></p>
<ul>
<li><strong>背景</strong>：训练 AI 需要它搜索成千上万次。如果每次都去连真实的百度或 Google，速度太慢且要花钱。</li>
<li><strong>作用</strong>：这是一个<strong>本地的搜索引擎</strong>。</li>
<li><strong>原理</strong>：它把大量的知识（文档）转化成数学向量（Dense Vector）存在本地。当模型想要“搜索”时，它能以极快的速度在本地找到相关资料返回给模型。</li>
</ul>
<p><strong>一句话</strong>：这是为了让 AI 训练时能毫秒级查资料而搭建的一个“局域网搜索引擎”。</p>
<hr />
<h3>3. 高层认知：一图看懂这部分代码的作用</h3>
<p>你可以把这个目录想象成在搭建一个 <strong>“超级实习生养成系统”</strong>：</p>
<ol>
<li><strong>大脑 (Model)</strong>：你领来了一个还不错的实习生（Qwen 2.5）。</li>
<li><strong>工具 (Tool)</strong>：你给了他一本厚厚的百科全书（local_dense_retriever）。</li>
<li><strong>任务 (Task)</strong>：你问他很难的问题。</li>
<li><strong>训练 (Script)</strong>：<ul>
<li>你盯着他，让他学会：遇到不懂的不要瞎蒙，去翻那本百科全书。</li>
<li>翻一次不够，可以根据查到的内容再翻第二次（多轮）。</li>
<li>如果你答得好，我给你加薪（GRPO 奖励机制）。</li>
</ul>
</li>
</ol>
<p><strong>总结：</strong>
这个目录就是利用 <strong>SGLang</strong>（极速推理引擎）和 <strong>Verl</strong>（强化学习框架），试图在开源模型上<strong>复现 DeepSeek-R1 那种“搜索+推理”的强大能力</strong>。</p>