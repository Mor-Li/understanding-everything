<h1>docs/sglang_multiturn/multiturn.rst</h1>
<p>这份文档确实比较硬核，主要是在讲如何在 <code>verl</code> 这个强化学习框架中，支持 <strong>多轮对话（Multi-turn）</strong> 和 <strong>工具调用（Tool Use）</strong> 的训练与推理（Rollout）。</p>
<p>简单来说，就是教你如何配置系统，让 AI 不仅仅是回答一个问题，而是能像 ChatGPT 一样和你来回对话，甚至在对话中调用计算器或搜索引擎，并且如何正确地计算这些复杂过程中的 Loss（损失函数）。</p>
<p>为了让你看懂，我把它拆解成一个 <strong>“任务清单（Todo List）”</strong>，按照你配置环境的逻辑顺序，一步步给你讲。</p>
<hr />
<h3>📋 任务清单 (Todo List)</h3>
<ol>
<li><strong>基础开关</strong>：开启多轮对话模式。</li>
<li><strong>装备工具</strong>：给 AI 配备工具（自定义工具或 MCP 标准工具）。</li>
<li><strong>处理多模态</strong>：如果工具返回图片/视频，该怎么处理。</li>
<li><strong>核心难点</strong>：理解并配置“多轮分词”（Tokenization），确保模型学对东西。</li>
<li><strong>排坑指南</strong>：处理特定模型（如 Qwen）的特殊 Bug 和配置。</li>
</ol>
<hr />
<h3>🧩 逐步详解</h3>
<h4>1. 基础开关 (Basic Configuration)</h4>
<p><strong>任务</strong>：告诉系统“我要开始多轮对话训练了，别只当成单轮问答处理”。</p>
<ul>
<li><strong>怎么做</strong>：
    在你的配置文件（YAML）里，找到 <code>actor_rollout_ref</code> -&gt; <code>rollout</code>，把 <code>multi_turn</code> 设为 <code>True</code>。
    <code>yaml
    multi_turn: True
    name: "sglang"  # 指定使用 sglang 引擎</code></li>
</ul>
<h4>2. 装备工具 (Tool Configuration)</h4>
<p><strong>任务</strong>：AI 需要“手”，比如计算器或搜索。你需要定义这些工具并挂载上去。</p>
<ul>
<li>
<p><strong>情况 A：你自己写的工具 (Custom Tool)</strong></p>
<ol>
<li>写一个 Python 类继承 <code>BaseTool</code>（比如 <code>GSM8KTool</code>）。</li>
<li>写一个 YAML 文件描述这个工具（名字、类型）。</li>
<li>在主配置里把 <code>tools_config_file</code> 指向这个 YAML。</li>
<li><em>如果是模拟交互环境（Simulated Interaction），配置 <code>interaction_config_file</code>。</em></li>
</ol>
</li>
<li>
<p><strong>情况 B：使用 MCP 工具 (MCP Tool)</strong></p>
<ul>
<li>MCP (Model Context Protocol) 是一种标准协议。如果你有现成的 MCP 服务器（比如 SSE 或 STDIO），只需要在配置文件里填好服务器地址和 API Key 即可，不需要自己重写代码。</li>
</ul>
</li>
</ul>
<h4>3. 处理多模态 (Multi-Modal Inputs)</h4>
<p><strong>任务</strong>：如果你的工具不仅仅返回文字，还返回图片或视频（比如 AI 让你看一张图），怎么传给模型？</p>
<ul>
<li><strong>怎么做</strong>：<ol>
<li>在工具代码的 <code>execute()</code> 函数里，返回 <code>ToolResponse</code> 对象时，把 <code>image</code> 或 <code>video</code> 放进去。</li>
<li><strong>重要细节</strong>：记得在代码里先处理一下图片/视频（<code>process_image</code> / <code>process_video</code>）。</li>
<li><strong>关键配置</strong>：在数据集配置里设置 <code>return_multi_modal_inputs: False</code>。<ul>
<li><em>为什么？</em> 因为在多轮对话中，图片是动态生成的，不需要数据集中预先加载好的图片来干扰。</li>
</ul>
</li>
</ol>
</li>
</ul>
<h4>4. 核心难点：多轮分词 (Multi-turn Tokenization)</h4>
<p><strong>任务</strong>：这是文档中最技术的部分。在多轮对话中，模型会生成很多句话。<strong>我们只想训练模型新生成的那些话（Assistant 回复），而不是训练用户的问题或历史记录。</strong></p>
<ul>
<li><strong>问题</strong>：由于对话历史很长，把它变成 Token 后，很难分清哪一段是刚才 AI 说的。</li>
<li><strong>解决方案 (Delta-based Strategy)</strong>：用“减法”。<ol>
<li>把 <code>[历史消息]</code> 变成 Token。</li>
<li>把 <code>[历史消息 + 最新回复]</code> 变成 Token。</li>
<li><strong>相减</strong>：后者比前者多出来的部分，就是我们要训练的“最新回复”。</li>
</ol>
</li>
<li><strong>安全检查 (Sanity Check)</strong>：<ul>
<li>系统会自动检查这个“减法”算得对不对。</li>
<li>如果你看到警告（Warning），可以通过配置 <code>tokenization_sanity_check_mode</code> 来调整检查的严格程度（比如忽略空格差异 <code>ignore_strippable</code>）。</li>
</ul>
</li>
</ul>
<h4>5. 排坑指南：特定模型 (Special Cases - Qwen)</h4>
<p><strong>任务</strong>：如果你用的是 Qwen（千问）系列模型，这里有个大坑需要注意。</p>
<ul>
<li><strong>问题</strong>：Qwen 模型（特别是 QwQ-32B 和 Qwen3）在应用聊天模板时，会<strong>偷偷删掉</strong>之前的“思考过程”（Reasoning Content / <code>&lt;think&gt;</code> 标签）。<ul>
<li>这就导致上面的“减法”失效了（因为历史记录里的内容变了）。</li>
</ul>
</li>
<li><strong>解决方法</strong>：<ul>
<li>系统会回退使用一个“固定的基础对话”来做减法计算，而不是用真实历史。</li>
<li><strong>补丁</strong>：对于 QwQ-32B，官方建议下载一个修复版的模型 Revision。</li>
</ul>
</li>
<li><strong>权衡 (Trade-off)</strong>：<ul>
<li><strong>训练 vs 推理的不一致</strong>：训练时模型能看到完整的历史思考过程，但推理（实际使用）时，聊天模板可能会把旧的思考过程截断。</li>
<li>你可以设置 <code>use_inference_chat_template = True</code> 让训练也截断思考过程，以匹配生产环境，但这样模型可能会变笨（因为忘了之前的思路）。</li>
</ul>
</li>
</ul>
<hr />
<h3>💡 总结</h3>
<p>这篇文档其实就是在说：
<strong>“我们要搞多轮对话训练了，打开开关，挂上工具。但是要注意，多轮对话算 Loss 很麻烦，我们用了‘减法’策略。如果你用 Qwen 模型，要注意它会吞掉思考标签，导致计算出错，请按我们的特殊方法配置。”</strong></p>