<h1>docs/sglang_multiturn/search_tool_example.rst</h1>
<p>这份文档主要讲的是：<strong>如何让 AI 模型在强化学习（RL）训练过程中，学会使用“搜索工具”来辅助回答问题。</strong></p>
<p>简单来说，就是给正在训练的模型装一个“本地搜索引擎”，让它在多轮对话中如果遇到不懂的，可以去查资料，然后利用查到的资料来优化自己的回答。</p>
<p>文档主要是一份<strong>操作指南（Tutorial）</strong>，教你如何搭建环境、下载数据、启动搜索服务，最后开始训练。</p>
<p>为了让你看懂，我把它拆解成一个 <strong>Task Todo List（任务清单）</strong>，然后一步步给你解释每一步在干嘛。</p>
<hr />
<h3>核心任务清单 (Task Todo List)</h3>
<p>整个流程可以分为 <strong>两个主要角色</strong> 的搭建：
1.  <strong>主角（训练端）</strong>：负责跑强化学习算法，训练模型。
2.  <strong>配角（搜索端）</strong>：负责提供资料查询服务（类似一个本地的 Google）。</p>
<p><strong>Todo 1：准备“主角”的运行环境 (Docker &amp; Python)</strong>
- [ ] 启动 Docker 容器。
- [ ] 更新 Python 并安装包管理工具 <code>uv</code>。
- [ ] 创建并激活虚拟环境 <code>verl-multiturn-rollout</code>。</p>
<p><strong>Todo 2：安装“主角”的软件 (Verl)</strong>
- [ ] 下载 <code>verl</code> 代码库。
- [ ] 安装依赖包和 Flash Attention（加速计算用）。</p>
<p><strong>Todo 3：准备“配角”的运行环境 (Conda &amp; Search Engine)</strong>
- [ ] <strong>注意</strong>：这里需要新开一个环境，跟上面的隔离。
- [ ] 安装 Miniconda。
- [ ] 创建并激活新环境 <code>retriever</code>。
- [ ] 安装 PyTorch 和 <code>faiss-gpu</code>（Facebook 开源的搜索库）。
- [ ] 下载巨大的搜索索引文件（维基百科数据，约 60-130GB）。
- [ ] <strong>启动搜索服务</strong>（把这个服务跑起来，等待主角来调用）。</p>
<p><strong>Todo 4：数据准备与配置</strong>
- [ ] 设置 WANDB（用于看训练曲线）。
- [ ] 预处理训练数据（切回到“主角”环境做）。</p>
<p><strong>Todo 5：开始训练</strong>
- [ ] 运行训练脚本（让主角开始跑，期间会不断请求配角进行搜索）。</p>
<hr />
<h3>逐步详细讲解 (Step-by-Step Guide)</h3>
<p>下面我把文中的代码块翻译成人类语言，告诉你每一步的目的是什么。</p>
<h4>第一阶段：搭建“主角”环境（训练环境）</h4>
<p><strong>1. 启动 Docker</strong>
*   <strong>原文操作</strong>：<code>docker run ...</code>
*   <strong>目的</strong>：为了保证环境干净，不污染你的物理机，这里用 Docker 搞一个独立的沙盒。</p>
<p><strong>2. 配置 Python 环境</strong>
*   <strong>原文操作</strong>：<code>apt update</code>, <code>python3 -m venv ...</code>, <code>pip install uv</code>
*   <strong>目的</strong>：在 Docker 里创建一个专门用来跑训练的 Python 虚拟环境。这里用 <code>uv</code> 是因为它比 <code>pip</code> 快很多。</p>
<p><strong>3. 安装 Verl 框架</strong>
*   <strong>原文操作</strong>：<code>git clone ...</code>, <code>uv pip install ...</code>
*   <strong>目的</strong>：<code>verl</code> 是字节跳动开源的一个强化学习框架。这一步就是把这个框架安装好，包括它依赖的 <code>sglang</code>（用于快速推理）和 <code>flash-attn</code>（用于加速显卡计算）。</p>
<hr />
<h4>第二阶段：搭建“配角”环境（搜索服务）</h4>
<p><strong>重点提示</strong>：文档特意强调了，<strong>搜索服务要用 Conda 环境</strong>，而<strong>训练服务用 venv 环境</strong>。这是因为搜索库 <code>faiss-gpu</code> 在某些环境下很难装，用 Conda 最稳。</p>
<p><strong>4. 设置本地检索引擎 (Local Retrieval Engine)</strong>
*   <strong>原文操作</strong>：安装 Miniconda -&gt; <code>conda create -n retriever</code> -&gt; <code>conda install faiss-gpu</code>
*   <strong>目的</strong>：搭建一个专门的“图书管理员”。因为它需要用到 GPU 加速搜索，所以这里装了 <code>faiss-gpu</code>。还装了 <code>fastapi</code>，因为这个管理员要通过 HTTP 接口（网页服务）来接收查询请求。</p>
<p><strong>5. 下载“图书馆”藏书 (Indexing and Corpus)</strong>
*   <strong>原文操作</strong>：<code>python .../download.py</code>
*   <strong>目的</strong>：下载维基百科的索引文件。
*   <strong>备注</strong>：文件非常大（下载 60G，解压后 130G），你需要准备好硬盘空间。这就是模型用来“查资料”的知识库。</p>
<p><strong>6. 启动搜索服务器</strong>
*   <strong>原文操作</strong>：<code>python .../retrieval_server.py ...</code>
*   <strong>目的</strong>：<strong>这一步很关键</strong>。这行命令会启动一个服务，监听在本地端口。
*   <strong>状态</strong>：启动后，它会占用显卡约 5-7GB 显存。它就像一个时刻待命的图书管理员，等着训练程序发来“帮我查查 xxx”的请求。</p>
<hr />
<h4>第三阶段：整合与发射</h4>
<p><strong>7. 准备工作</strong>
*   <strong>原文操作</strong>：<code>export WANDB_API_KEY...</code>, <code>python .../preprocess_search_r1_dataset.py</code>
*   <strong>目的</strong>：
    *   配置 WANDB 是为了你在网页上能看到训练过程是变好了还是变坏了。
    *   预处理数据是把原始的问答数据，转换成 <code>verl</code> 框架能读懂的格式。<strong>注意：这步要切回“主角”环境 (<code>verl-multiturn-rollout</code>) 执行。</strong></p>
<p><strong>8. 启动训练 (Testing on 8 x H20)</strong>
*   <strong>原文操作</strong>：<code>bash .../run_qwen2.5-3b_instruct_search_multiturn.sh</code>
*   <strong>目的</strong>：这是最后一步。启动一个脚本，使用 8 张 H20 显卡开始训练 Qwen2.5-3b 模型。
*   <strong>流程</strong>：
    1.  模型（Actor）接收问题。
    2.  模型觉得需要查资料，发起工具调用。
    3.  请求发送给刚才启动的“搜索服务器”。
    4.  搜索服务器返回结果。
    5.  模型根据结果生成答案。
    6.  RL 算法根据答案好坏调整模型参数。</p>
<hr />
<h4>第四阶段：自定义配置（进阶）</h4>
<p>文档最后一段 <code>Custom Search Configuration</code> 是告诉你，如果你想改配置该怎么做：</p>
<ul>
<li><strong>开启多轮对话</strong>：在配置文件里把 <code>multi_turn: enable: True</code> 打开。</li>
<li><strong>修改搜索地址</strong>：如果你不想用本地搭建的搜索服务，想用别的（比如谷歌搜索API），你可以在 <code>search_tool_config.yaml</code> 里修改 <code>retrieval_service_url</code>。</li>
<li><strong>并发控制</strong>：设置 <code>num_workers</code> 来决定同时能处理多少个搜索请求。</li>
</ul>
<h3>总结</h3>
<p>这篇文档其实就是教你做一个 <strong>“左右互搏”</strong> 的系统：
*   左手（环境 A）：跑 AI 模型训练。
*   右手（环境 B）：跑一个本地搜索服务器。
*   训练时，左手不断向右手问问题，右手查资料给左手，左手学习如何利用这些资料更好地回答问题。</p>