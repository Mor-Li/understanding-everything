"""
s4_generate_readme.py
é€’å½’ç”Ÿæˆå„å±‚çº§ç›®å½•çš„ README.mdï¼ˆè‡ªåº•å‘ä¸Šï¼‰
"""

import argparse
import logging
import os
from pathlib import Path

import tiktoken
from openai import OpenAI
from tqdm import tqdm

from utils import get_output_path

# åˆå§‹åŒ– tokenizer
tokenizer = tiktoken.get_encoding("o200k_base")

# é…ç½® logging
logging.basicConfig(
    level=logging.INFO,
    format="%(message)s"
)
logger = logging.getLogger(__name__)

# å¸¸é‡
MAX_TOKENS = 200_000  # 200K token é™åˆ¶

# Prompt æ¨¡æ¿
README_PROMPT = """ä»¥ä¸‹æ˜¯ {folder_path} ç›®å½•ä¸‹çš„å†…å®¹ï¼š

{content}

è¯·ä½ ç”¨æœ€é€šä¿—æ˜“æ‡‚çš„è¯­è¨€ã€ç”¨æ¯”å–»çš„æ–¹å¼æè¿°ä¸€ä¸‹ï¼š
1. å½“å‰è¿™ä¸ªæ–‡ä»¶å¤¹ä¸»è¦è´Ÿè´£ä»€ä¹ˆåŠŸèƒ½ï¼Ÿ
2. è¿™ä¸ªæ–‡ä»¶å¤¹ä¸‹çš„å„ä¸ªæ–‡ä»¶/å­æ–‡ä»¶å¤¹åˆ†åˆ«æ˜¯å¹²ä»€ä¹ˆçš„ï¼Ÿ
3. ç»™æˆ‘ä¸€ä¸ªé«˜å±‚çš„è®¤çŸ¥ï¼Œè®©æˆ‘èƒ½å¿«é€Ÿç†è§£è¿™éƒ¨åˆ†ä»£ç çš„ä½œç”¨ã€‚

è¯·ç”¨ç®€æ´ã€é€šä¿—ã€æ˜“æ‡‚çš„è¯­æ°”å›ç­”ï¼Œè¯´ä¸­æ–‡ã€‚"""


def count_tokens(text: str) -> int:
    """è®¡ç®—æ–‡æœ¬çš„ token æ•°é‡"""
    return len(tokenizer.encode(text))


def truncate_content(contents: list[tuple[str, str, int]], target_tokens: int) -> list[tuple[str, str]]:
    """
    ç­‰æ¯”ä¾‹æˆªæ–­å†…å®¹ä»¥æ»¡è¶³ token é™åˆ¶

    Args:
        contents: [(name, content, token_count), ...]
        target_tokens: ç›®æ ‡ token æ•°é‡

    Returns:
        [(name, truncated_content), ...]
    """
    total_tokens = sum(tc for _, _, tc in contents)
    ratio = target_tokens / total_tokens

    logger.warning(f"âš ï¸  å†…å®¹è¶…å‡º {MAX_TOKENS:,} tokens é™åˆ¶")
    logger.warning(f"   æ€»é‡: {total_tokens:,} tokens")
    logger.warning(f"   å‹ç¼©æ¯”ä¾‹: {ratio:.2%}")

    truncated = []
    for name, content, token_count in contents:
        # è®¡ç®—è¯¥æ–‡ä»¶åº”ä¿ç•™çš„ token æ•°é‡
        keep_tokens = int(token_count * ratio)

        # ç¼–ç åæˆªæ–­ï¼Œå†è§£ç 
        tokens = tokenizer.encode(content)
        truncated_tokens = tokens[:keep_tokens]
        truncated_content = tokenizer.decode(truncated_tokens)

        truncated.append((name, truncated_content))
        logger.warning(f"   - {name}: {token_count:,} â†’ {keep_tokens:,} tokens ({ratio:.2%})")

    return truncated


def collect_folder_content(folder_path: Path, explain_base: Path) -> str:
    """
    æ”¶é›†æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰å†…å®¹ï¼ˆæ–‡ä»¶çš„ .md + å­æ–‡ä»¶å¤¹çš„ README.mdï¼‰

    Args:
        folder_path: å½“å‰æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆç›¸å¯¹äº repo æ ¹ç›®å½•ï¼‰
        explain_base: explain è¾“å‡ºçš„åŸºç¡€è·¯å¾„

    Returns:
        åˆå¹¶åçš„å†…å®¹å­—ç¬¦ä¸²
    """
    explain_folder = explain_base / folder_path

    if not explain_folder.exists():
        return ""

    contents = []  # [(name, content, token_count), ...]

    # æ”¶é›†ç›´æ¥å­æ–‡ä»¶çš„ .mdï¼ˆä¸åŒ…æ‹¬ README.mdï¼‰
    for md_file in sorted(explain_folder.glob("*.md")):
        if md_file.name == "README.md":
            continue

        with open(md_file, "r", encoding="utf-8") as f:
            content = f.read()
            token_count = count_tokens(content)
            # å»æ‰ .md åç¼€ä½œä¸ºæ˜¾ç¤ºåç§°
            name = md_file.name[:-3] if md_file.name.endswith(".md") else md_file.name
            contents.append((f"ğŸ“„ {name}", content, token_count))

    # æ”¶é›†å­æ–‡ä»¶å¤¹çš„ README.md
    for subfolder in sorted(explain_folder.iterdir()):
        if subfolder.is_dir():
            readme = subfolder / "README.md"
            if readme.exists():
                with open(readme, "r", encoding="utf-8") as f:
                    content = f.read()
                    token_count = count_tokens(content)
                    contents.append((f"ğŸ“ {subfolder.name}/", content, token_count))

    if not contents:
        return ""

    # è®¡ç®—æ€» token æ•°
    total_tokens = sum(tc for _, _, tc in contents)

    # å¦‚æœè¶…è¿‡é™åˆ¶ï¼Œæˆªæ–­
    if total_tokens > MAX_TOKENS:
        contents_text = truncate_content(contents, MAX_TOKENS)
    else:
        contents_text = [(name, content) for name, content, _ in contents]

    # æ‹¼æ¥å†…å®¹
    result = []
    for name, content in contents_text:
        result.append(f"## {name}\n\n{content}\n\n")

    return "".join(result)


def ask_gemini(folder_path: str, content: str, model: str = "gemini-2.5-pro") -> str:
    """
    è°ƒç”¨ Gemini API ç”Ÿæˆ README

    Args:
        folder_path: æ–‡ä»¶å¤¹è·¯å¾„
        content: æ–‡ä»¶å¤¹å†…å®¹
        model: ä½¿ç”¨çš„æ¨¡å‹

    Returns:
        README å†…å®¹ï¼ˆMarkdown æ ¼å¼ï¼‰
    """
    api_key = os.getenv("OPENAI_API_KEY")
    base_url = os.getenv("OPENAI_BASE_URL")

    if not api_key:
        raise ValueError("éœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY")

    client = OpenAI(api_key=api_key, base_url=base_url)

    prompt = README_PROMPT.format(folder_path=folder_path, content=content)

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=32000,
            temperature=0.7,
        )

        finish_reason = response.choices[0].finish_reason
        content = response.choices[0].message.content or ""

        if finish_reason == "length":
            content += "\n\n_ï¼ˆæ³¨ï¼šå“åº”å› é•¿åº¦é™åˆ¶è¢«æˆªæ–­ï¼‰_"

        return content.strip()
    except Exception as e:
        return f"# README ç”Ÿæˆå¤±è´¥\n\né”™è¯¯ä¿¡æ¯: {str(e)}"


def generate_readme_recursive(
    folder_path: Path,
    explain_base: Path,
    force: bool = False,
    model: str = "gemini-2.5-pro",
) -> bool:
    """
    é€’å½’ç”Ÿæˆ README.mdï¼ˆè‡ªåº•å‘ä¸Šï¼‰

    Args:
        folder_path: å½“å‰æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆç›¸å¯¹äº repo æ ¹ç›®å½•ï¼‰
        explain_base: explain è¾“å‡ºçš„åŸºç¡€è·¯å¾„
        force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ç”Ÿæˆ
        model: ä½¿ç”¨çš„æ¨¡å‹

    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    explain_folder = explain_base / folder_path

    if not explain_folder.exists():
        return False

    # å…ˆé€’å½’å¤„ç†æ‰€æœ‰å­æ–‡ä»¶å¤¹
    for subfolder in sorted(explain_folder.iterdir()):
        if subfolder.is_dir():
            sub_rel_path = folder_path / subfolder.name
            generate_readme_recursive(sub_rel_path, explain_base, force, model)

    # æ£€æŸ¥å½“å‰æ–‡ä»¶å¤¹æ˜¯å¦å·²æœ‰ README.md
    readme_path = explain_folder / "README.md"
    if readme_path.exists() and not force:
        logger.info(f"â­ï¸  è·³è¿‡ {folder_path}ï¼ˆå·²å­˜åœ¨ README.mdï¼‰")
        return True

    # æ”¶é›†å½“å‰æ–‡ä»¶å¤¹çš„å†…å®¹
    content = collect_folder_content(folder_path, explain_base)

    if not content:
        logger.info(f"â­ï¸  è·³è¿‡ {folder_path}ï¼ˆæ²¡æœ‰å†…å®¹ï¼‰")
        return False

    # è°ƒç”¨ Gemini ç”Ÿæˆ README
    logger.info(f"ğŸ¤– æ­£åœ¨ç”Ÿæˆ {folder_path} çš„ README...")
    readme_content = ask_gemini(str(folder_path), content, model)

    # ä¿å­˜ README.md
    with open(readme_path, "w", encoding="utf-8") as f:
        f.write(f"# {folder_path}\n\n")
        f.write(readme_content)

    logger.info(f"âœ“ å·²ä¿å­˜åˆ° {readme_path}")
    return True


def find_all_folders(explain_base: Path, root_folder: Path) -> list[Path]:
    """
    æ‰¾åˆ°æ‰€æœ‰éœ€è¦ç”Ÿæˆ README çš„æ–‡ä»¶å¤¹ï¼ˆè‡ªåº•å‘ä¸Šæ’åºï¼‰

    Args:
        explain_base: explain è¾“å‡ºçš„åŸºç¡€è·¯å¾„
        root_folder: æ ¹æ–‡ä»¶å¤¹ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰

    Returns:
        æ–‡ä»¶å¤¹è·¯å¾„åˆ—è¡¨ï¼ˆç›¸å¯¹è·¯å¾„ï¼ŒæŒ‰æ·±åº¦ä»æ·±åˆ°æµ…æ’åºï¼‰
    """
    explain_folder = explain_base / root_folder

    if not explain_folder.exists():
        return []

    folders = []

    def walk(current_path: Path):
        """é€’å½’éå†æ–‡ä»¶å¤¹"""
        for item in current_path.iterdir():
            if item.is_dir():
                rel_path = item.relative_to(explain_base)
                folders.append(rel_path)
                walk(item)

    # ä»æ ¹æ–‡ä»¶å¤¹å¼€å§‹éå†
    folders.append(root_folder)
    walk(explain_folder)

    # æŒ‰æ·±åº¦ä»æ·±åˆ°æµ…æ’åºï¼ˆæ·±åº¦ = è·¯å¾„ä¸­çš„ / æ•°é‡ï¼‰
    folders.sort(key=lambda p: len(p.parts), reverse=True)

    return folders


def main():
    parser = argparse.ArgumentParser(description="é€’å½’ç”Ÿæˆå„å±‚çº§ç›®å½•çš„ README.md")
    parser.add_argument("repo_path", help="Git ä»“åº“è·¯å¾„")
    parser.add_argument("--subdir", default="mshrl", help="è¦åˆ†æçš„å­ç›®å½•")
    parser.add_argument("--output", "-o", help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼šoutput/<repo_name>/explainï¼‰")
    parser.add_argument("--force", action="store_true", help="å¼ºåˆ¶é‡æ–°ç”Ÿæˆ")
    parser.add_argument("--model", "-m", default="gemini-2.5-pro", help="ä½¿ç”¨çš„æ¨¡å‹")

    args = parser.parse_args()

    # é»˜è®¤è¾“å‡ºè·¯å¾„ï¼šoutput/<repo_name>/explain-<date>
    if args.output is None:
        args.output = get_output_path(args.repo_path, args.subdir, "explain")

    explain_base = Path(args.output)
    root_folder = Path(args.subdir)

    print(f"ğŸš€ å¼€å§‹ä¸º {args.subdir}/ ç”Ÿæˆå±‚çº§ README")
    print()

    # æ‰¾åˆ°æ‰€æœ‰æ–‡ä»¶å¤¹ï¼ˆè‡ªåº•å‘ä¸Šï¼‰
    folders = find_all_folders(explain_base, root_folder)

    if not folders:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„æ–‡ä»¶å¤¹")
        return

    print(f"ğŸ“Š æ‰¾åˆ° {len(folders)} ä¸ªæ–‡ä»¶å¤¹ï¼ˆè‡ªåº•å‘ä¸Šï¼‰")
    print()

    # é€ä¸ªç”Ÿæˆ READMEï¼ˆå¸¦è¿›åº¦æ¡ï¼‰
    success_count = 0
    with tqdm(total=len(folders), desc="ç”Ÿæˆ README", unit="folder") as pbar:
        for folder_path in folders:
            if generate_readme_recursive(folder_path, explain_base, args.force, args.model):
                success_count += 1
            pbar.update(1)

    print(f"\nğŸ‰ å®Œæˆï¼æˆåŠŸç”Ÿæˆ {success_count}/{len(folders)} ä¸ª README")


if __name__ == "__main__":
    main()
